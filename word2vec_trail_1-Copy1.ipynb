{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "20517a3d0aff79fef4251fd889b6e8422900c11b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "059330c4f70d8292575bb5e83a6ad832c7e29041"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9e4bf18683202567e857e8668f09d95100b48d73"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "6ac466ab41a52d3b2742fb96ca9efd573f8ea393"
   },
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "  def __init__(self):\n",
    "    # load in pre-trained word vectors\n",
    "    print('Loading word vectors...')\n",
    "    word2vec = {}\n",
    "    embedding = []\n",
    "    idx2word = []\n",
    "    with open('glove840b300dtxt/glove.840B.300d.txt',encoding='utf-8') as f:\n",
    "      # is just a space-separated text file in the format:\n",
    "      # word vec[0] vec[1] vec[2] ...\n",
    "      for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "    print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "    # save for later\n",
    "    self.word2vec = word2vec\n",
    "    self.embedding = np.array(embedding)\n",
    "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "    self.V, self.D = self.embedding.shape\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.lower().split()\n",
    "      vecs = []\n",
    "      for word in tokens:\n",
    "        if word in self.word2vec:\n",
    "          vec = self.word2vec[word]\n",
    "          vecs.append(vec)\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2c674be6ceb9ff2c65774780909307245434ab85"
   },
   "outputs": [],
   "source": [
    "class Word2VecVectorizerEN:\n",
    "  def __init__(self):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "      'GoogleNews-vectors-negative300.bin',\n",
    "      binary=True\n",
    "    )\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('king')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2c674be6ceb9ff2c65774780909307245434ab85"
   },
   "outputs": [],
   "source": [
    "class Word2VecVectorizerID:\n",
    "  def __init__(self):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "      'id_sahdan.bin',\n",
    "      binary=True\n",
    "    )\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('yang')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936\n"
     ]
    }
   ],
   "source": [
    "ignore_words = set(stopwords.words('english')).union(set(stopwords.words('indonesian')))\n",
    "print(len(ignore_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "49cac2747c9b75de6a074fd8ecce57b26c1ede31"
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')\n",
    "df_cat=pd.read_json('categories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    stopwords = list(ignore_words)\n",
    "    querywords = text.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in stopwords]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "df_train.loc[:,'title']=df_train.title.apply(remove_stop_words)\n",
    "df_test.loc[:,'title']=df_test.title.apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 nyx sex bomb pallete natural palette\n",
       "1    etude house precious mineral cushion pearl aur...\n",
       "2                             milani rose powder blush\n",
       "3                  etude house baby sweet sugar powder\n",
       "4            bedak revlon color stay aqua mineral make\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.title.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "509be9648ff1ececf1eed491d130429695a62748"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(df_train,random_state=2019,stratify=df_train.Category,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train['Group']=df_train.image_path.map(lambda x: x[:7])\n",
    "df_test['Group']=df_test.image_path.map(lambda x: x[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=['beauty_','mobile_','fashion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some linear models\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "\n",
    "# SCM for classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build pipeline for parameter search in n_grams and and various models\n",
    "lr=LogisticRegression()\n",
    "nb=MultinomialNB()\n",
    "svc=SVC()\n",
    "# let's check first three and see which one is best\n",
    "gnb=GaussianNB()\n",
    "bnb=BernoulliNB()\n",
    "br=BayesianRidge()\n",
    "rf=RandomForestClassifier(n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Results for group:  beauty_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2503 / 286583\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 242433 / 286583\n",
      "Results for English only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.73061905277\n",
      "Results for English and Indonesian combined only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.729844408077\n",
      "Results for group:  mobile_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 985 / 160330\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 83465 / 160330\n",
      "Results for English only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)}\n",
      "Best scores:  0.741869893345\n",
      "Results for English and Indonesian combined only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.738027817626\n",
      "Results for group:  fashion\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 303 / 219702\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 201239 / 219702\n",
      "Results for English only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.551537992371\n",
      "Results for English and Indonesian combined only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.551510682652\n"
     ]
    }
   ],
   "source": [
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "param={'model':[lr,rf]} # Can't use nb because negative values\n",
    "for group in groups:\n",
    "    # English vectorization\n",
    "    print('Results for group: ', group)\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(df_train[df_train.Group==group].title)\n",
    "    \n",
    "    # Indonesian vectorization\n",
    "    vectorizerID = Word2VecVectorizerID()\n",
    "    X_train_ID = vectorizerID.fit_transform(df_train[df_train.Group==group].title)\n",
    "    y_train = df_train[df_train.Group==group].Category.values\n",
    "   \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    \n",
    "    print (\"Results for English only:\")\n",
    "    pipe=Pipeline([('model',lr)])\n",
    "    grid_search=GridSearchCV(pipe,param_grid=param)\n",
    "    grid_search.fit(X_train_EN,y_train)\n",
    "    print('Best parameters: ',grid_search.best_params_)\n",
    "    print('Best scores: ',grid_search.best_score_)\n",
    "    \n",
    "    print (\"Results for English and Indonesian combined only:\")\n",
    "    pipe=Pipeline([('model',lr)])\n",
    "    grid_search=GridSearchCV(pipe,param_grid=param)\n",
    "    grid_search.fit(X_train_com,y_train)\n",
    "    print('Best parameters: ',grid_search.best_params_)\n",
    "    print('Best scores: ',grid_search.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('model', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train_EN,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just donwloaded new corpus for Indonesian . From this link http://vectors.nlpl.eu/repository/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "6ac466ab41a52d3b2742fb96ca9efd573f8ea393"
   },
   "outputs": [],
   "source": [
    "# Just donwloaded new corpus for Indonesian . From this link http://vectors.nlpl.eu/repository/\n",
    "\n",
    "class Word2VecVectorizerID2:\n",
    "  def __init__(self):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "      'model.txt',\n",
    "      binary=False,\n",
    "      unicode_errors='replace'  \n",
    "        \n",
    "    )\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('yang')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2 / 219702\n"
     ]
    }
   ],
   "source": [
    "vectorizerID2 = Word2VecVectorizerID2()\n",
    "X_train_ID2 = vectorizerID2.fit_transform(df_train[df_train.Group==group].title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for group:  beauty_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2503 / 286583\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 5 / 286583\n",
      "Results for English and Indonesian combined only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.735926415733\n",
      "Results for group:  mobile_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 985 / 160330\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 58 / 160330\n",
      "Results for English and Indonesian combined only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)}\n",
      "Best scores:  0.765951475083\n",
      "Results for group:  fashion\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 303 / 219702\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2 / 219702\n",
      "Results for English and Indonesian combined only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.573563281172\n"
     ]
    }
   ],
   "source": [
    "# Now let's do it with new Indonesian corpus\n",
    "param={'model':[lr,rf]} # Can't use nb because negative values\n",
    "for group in groups:\n",
    "    # English vectorization\n",
    "    print('Results for group: ', group)\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(df_train[df_train.Group==group].title)\n",
    "    \n",
    "    # Indonesian vectorization using another corpus\n",
    "    vectorizerID2 = Word2VecVectorizerID2()\n",
    "    X_train_ID = vectorizerID2.fit_transform(df_train[df_train.Group==group].title)\n",
    "    y_train = df_train[df_train.Group==group].Category.values\n",
    "   \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    \n",
    "    print (\"Results for English and Indonesian combined only:\")\n",
    "    pipe=Pipeline([('model',lr)])\n",
    "    grid_search=GridSearchCV(pipe,param_grid=param)\n",
    "    grid_search.fit(X_train_com,y_train)\n",
    "    print('Best parameters: ',grid_search.best_params_)\n",
    "    print('Best scores: ',grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 5 / 286583\n",
      "Results for new Indonesian corpus only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.707166859165\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 58 / 160330\n",
      "Results for new Indonesian corpus only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)}\n",
      "Best scores:  0.73011289216\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2 / 219702\n",
      "Results for new Indonesian corpus only:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "Best scores:  0.553613531056\n"
     ]
    }
   ],
   "source": [
    "# Now let's do it only with new Indonesian corpus\n",
    "param={'model':[lr,rf]} # Can't use nb because negative values\n",
    "for group in groups:\n",
    "\n",
    "    \n",
    "    # Indonesian vectorization using another corpus\n",
    "    vectorizerID2 = Word2VecVectorizerID2()\n",
    "    X_train_ID = vectorizerID2.fit_transform(df_train[df_train.Group==group].title)\n",
    "    y_train = df_train[df_train.Group==group].Category.values\n",
    "\n",
    "    \n",
    "    print (\"Results for new Indonesian corpus only:\")\n",
    "    pipe=Pipeline([('model',lr)])\n",
    "    grid_search=GridSearchCV(pipe,param_grid=param)\n",
    "    grid_search.fit(X_train_ID,y_train)\n",
    "    print('Best parameters: ',grid_search.best_params_)\n",
    "    print('Best scores: ',grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_rf=['beauty_','fashion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for group:  beauty_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2503 / 286583\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 5 / 286583\n",
      "Results for English and Indonesian combined only for rf optimization:\n",
      "Best parameters:  {'model__n_estimators': 200}\n",
      "Best scores:  0.73679876336\n",
      "Results for group:  fashion\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 303 / 219702\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2 / 219702\n",
      "Results for English and Indonesian combined only for rf optimization:\n",
      "Best parameters:  {'model__n_estimators': 160}\n",
      "Best scores:  0.575456755059\n"
     ]
    }
   ],
   "source": [
    "# Let's try some optimization on random forrest for beauty and fashion\n",
    "# Now let's do it with new Indonesian corpus\n",
    "param={'model__n_estimators':[i for i in range(40,220,40)]} # Can't use nb because negative values\n",
    "groups_rf=['beauty_','fashion']\n",
    "for group in groups_rf:\n",
    "    # English vectorization\n",
    "    print('Results for group: ', group)\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(df_train[df_train.Group==group].title)\n",
    "    \n",
    "    # Indonesian vectorization using another corpus\n",
    "    vectorizerID2 = Word2VecVectorizerID2()\n",
    "    X_train_ID = vectorizerID2.fit_transform(df_train[df_train.Group==group].title)\n",
    "    y_train = df_train[df_train.Group==group].Category.values\n",
    "   \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    \n",
    "    print (\"Results for English and Indonesian combined only for rf optimization:\")\n",
    "    pipe=Pipeline([('model',rf)])\n",
    "    grid_search=GridSearchCV(pipe,param_grid=param)\n",
    "    grid_search.fit(X_train_com,y_train)\n",
    "    print('Best parameters: ',grid_search.best_params_)\n",
    "    print('Best scores: ',grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for group:  beauty_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2503 / 286583\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 5 / 286583\n",
      "Results for English and Indonesian combined only for rf optimization:\n",
      "Best parameters:  {'model__n_estimators': 260}\n",
      "Best scores:  0.737653664035\n"
     ]
    }
   ],
   "source": [
    "# Let's try some optimization on random forrest for beauty and fashion\n",
    "# Now let's do it with new Indonesian corpus\n",
    "param={'model__n_estimators':[i for i in range(220,300,20)]} # Can't use nb because negative values\n",
    "groups_rf=['beauty_','fashion']\n",
    "for group in ['beauty_']:\n",
    "    # English vectorization\n",
    "    print('Results for group: ', group)\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(df_train[df_train.Group==group].title)\n",
    "    \n",
    "    # Indonesian vectorization using another corpus\n",
    "    vectorizerID2 = Word2VecVectorizerID2()\n",
    "    X_train_ID = vectorizerID2.fit_transform(df_train[df_train.Group==group].title)\n",
    "    y_train = df_train[df_train.Group==group].Category.values\n",
    "   \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    \n",
    "    print (\"Results for English and Indonesian combined only for rf optimization:\")\n",
    "    pipe=Pipeline([('model',rf)])\n",
    "    grid_search=GridSearchCV(pipe,param_grid=param)\n",
    "    grid_search.fit(X_train_com,y_train)\n",
    "    print('Best parameters: ',grid_search.best_params_)\n",
    "    print('Best scores: ',grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beauty_', 'mobile_', 'fashion']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(df_train,random_state=2019,stratify=df_train.Category,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for group:  beauty_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2503 / 286583\n",
      "Numer of samples with no words found: 100 / 76545\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 5 / 286583\n",
      "Numer of samples with no words found: 0 / 76545\n",
      "Generating predictions for validation set\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2015 / 229266\n",
      "Numer of samples with no words found: 488 / 57317\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 4 / 229266\n",
      "Numer of samples with no words found: 1 / 57317\n",
      "Results for group:  mobile_\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 985 / 160330\n",
      "Numer of samples with no words found: 235 / 40417\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 58 / 160330\n",
      "Numer of samples with no words found: 16 / 40417\n",
      "Generating predictions for validation set\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 788 / 128265\n",
      "Numer of samples with no words found: 197 / 32065\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 48 / 128265\n",
      "Numer of samples with no words found: 10 / 32065\n",
      "Results for group:  fashion\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 303 / 219702\n",
      "Numer of samples with no words found: 142 / 55440\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2 / 219702\n",
      "Numer of samples with no words found: 0 / 55440\n",
      "Generating predictions for validation set\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 230 / 175761\n",
      "Numer of samples with no words found: 73 / 43941\n",
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 2 / 175761\n",
      "Numer of samples with no words found: 0 / 43941\n"
     ]
    }
   ],
   "source": [
    "# Best configuration for 'beauty_' is RandomForrest(n_estimators=260) CV score : 0.737653664035\n",
    "# Best configuration for 'mobile_' is LogisticRegression() CV score : 0.765951475083\n",
    "# Best configuration for 'fashion' is RandomForrest(n_estimators=160) CV score : 0.575456755059. It seems to be good\n",
    "pipe_beauty=Pipeline([('model',RandomForestClassifier(n_estimators=260))])\n",
    "pipe_mobile=Pipeline([('model',LogisticRegression())])\n",
    "pipe_fashion=Pipeline([('model',RandomForestClassifier(n_estimators=160))])\n",
    "groups=['beauty_','mobile_','fashion']\n",
    "pipes=[pipe_beauty,pipe_mobile,pipe_fashion]\n",
    "predictions_val={}\n",
    "predictions_proba_val={}\n",
    "predictions={}\n",
    "predictions_proba={}\n",
    "classes={}\n",
    "classes_val={}\n",
    "for i in range(3):\n",
    "    # English vectorization\n",
    "    print('Results for group: ', groups[i])\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(df_train[df_train.Group==groups[i]].title)\n",
    "    X_test_EN=vectorizerEN.transform(df_test[df_test.Group==groups[i]].title)\n",
    "    \n",
    "    # Indonesian vectorization using another corpus\n",
    "    vectorizerID2 = Word2VecVectorizerID2()\n",
    "    X_train_ID = vectorizerID2.fit_transform(df_train[df_train.Group==groups[i]].title)\n",
    "    X_test_ID = vectorizerID2.transform(df_test[df_test.Group==groups[i]].title)\n",
    "    y_train = df_train[df_train.Group==groups[i]].Category.values\n",
    "   \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    \n",
    "    df_test_combined=pd.DataFrame(X_test_EN)\n",
    "    df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')\n",
    "    X_test_com=df_test_combined.values\n",
    "    \n",
    "    \n",
    "    \n",
    "    model=pipes[i]\n",
    "    model.fit(X_train_com,y_train)\n",
    "    classes[groups[i]]=model.classes_\n",
    "    predictions[groups[i]]=model.predict(X_test_com)\n",
    "    predictions_proba[groups[i]]=model.predict_proba(X_test_com)\n",
    "    \n",
    "    print(\"Generating predictions for validation set\")\n",
    "    \n",
    "    # We need validation set and probabilities for validation set for ensembling\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(train[train.Group==groups[i]].title)\n",
    "    X_test_EN=vectorizerEN.transform(test[test.Group==groups[i]].title)\n",
    "    \n",
    "    # Indonesian vectorization using another corpus\n",
    "    vectorizerID2 = Word2VecVectorizerID2()\n",
    "    X_train_ID = vectorizerID2.fit_transform(train[train.Group==groups[i]].title)\n",
    "    X_test_ID = vectorizerID2.transform(test[test.Group==groups[i]].title)\n",
    "    y_train = train[train.Group==groups[i]].Category.values\n",
    "    y_test = test[test.Group==groups[i]].Category.values\n",
    "   \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    \n",
    "    df_test_combined=pd.DataFrame(X_test_EN)\n",
    "    df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')\n",
    "    X_test_com=df_test_combined.values\n",
    "    \n",
    "    model=pipes[i]\n",
    "    model.fit(X_train_com,y_train)\n",
    "    classes_val[groups[i]]=model.classes_\n",
    "    predictions_val[groups[i]]=model.predict(X_test_com)\n",
    "    predictions_proba_val[groups[i]]=model.predict_proba(X_test_com)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data of: beauty_ 0.744054992411\n",
      "Accuracy on test data of: mobile_ 0.766505535631\n",
      "Accuracy on test data of: fashion 0.579777428825\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    print('Accuracy on test data of:',group,accuracy_score(test[test.Group==group].Category,predictions_val[group]))\n",
    "\n",
    "# Accuracy on test data of: beauty_ 0.744054992411\n",
    "# Accuracy on test data of: mobile_ 0.766505535631\n",
    "# Accuracy on test data of: fashion 0.579777428825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes={}\n",
    "for i in range(3):\n",
    "    classes[groups[i]]=pipes[i].classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beauty_': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16], dtype=int64),\n",
       " 'mobile_': array([31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "        48, 49, 50, 51, 52, 53, 54, 55, 56, 57], dtype=int64),\n",
       " 'fashion': array([17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], dtype=int64)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all data both validation set and training set\n",
    "# This data will be used for modeling ensembling and for final ensemble result\n",
    "for i in range(3):\n",
    "    # for ensembling\n",
    "    df=pd.DataFrame(predictions_proba[groups[i]])\n",
    "    df.columns=classes[groups[i]]\n",
    "    df['pred']=df.idxmax(axis=1)\n",
    "    df['itemid']=df_test[df_test.Group==groups[i]].itemid.values\n",
    "    df.to_csv(groups[i]+'_test_proba_w2v_all_data.csv',index=False)\n",
    "    # for ensemble modeling\n",
    "    df=pd.DataFrame(predictions_proba_val[groups[i]])\n",
    "    df.columns=classes[groups[i]]\n",
    "    df['pred']=df.idxmax(axis=1)\n",
    "    df['itemid']=test[test.Group==groups[i]].itemid.values\n",
    "    df.to_csv(groups[i]+'_test_proba_w2v_val_data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>Category</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539829</th>\n",
       "      <td>1058517290</td>\n",
       "      <td>xiaomi mi a1 garansi resmi 1 tam</td>\n",
       "      <td>34</td>\n",
       "      <td>mobile_image/3912586cdf51144db783b2bac1ee4d3f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473036</th>\n",
       "      <td>286463264</td>\n",
       "      <td>blus sexy model shoulder</td>\n",
       "      <td>26</td>\n",
       "      <td>fashion_image/cb790137111e2525cd895c3375fe84c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252009</th>\n",
       "      <td>1537965166</td>\n",
       "      <td>best sale jafra royal jelly radiance foundatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/5adfe3e65ad2f51a1e67db85a3de8e18.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355772</th>\n",
       "      <td>1465709373</td>\n",
       "      <td>dress midi bodycon casual elegan warna polos p...</td>\n",
       "      <td>22</td>\n",
       "      <td>fashion_image/cbedaa2404fb377dc6c271a1081f7baa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553954</th>\n",
       "      <td>1195506745</td>\n",
       "      <td>promo discon samsung galaxy s7 flat sein garan...</td>\n",
       "      <td>35</td>\n",
       "      <td>mobile_image/bb327fec3989b18f714deb3c07203fb8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620741</th>\n",
       "      <td>1833821649</td>\n",
       "      <td>samsung galaxy a6 plus 2018 new garansi nasional</td>\n",
       "      <td>35</td>\n",
       "      <td>mobile_image/8959112348969556df29f24d06ecff8f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486345</th>\n",
       "      <td>129360583</td>\n",
       "      <td>kemeja hitam wanita katun adem lengan pendek b...</td>\n",
       "      <td>27</td>\n",
       "      <td>fashion_image/7a4194bf7b509f29bfc5dcd9cc0355d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647884</th>\n",
       "      <td>291297752</td>\n",
       "      <td>xiaomi redmi mi5</td>\n",
       "      <td>34</td>\n",
       "      <td>mobile_image/8733bba77a727e4771d51b5a8b48c8a5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67883</th>\n",
       "      <td>1633487774</td>\n",
       "      <td>jd59 bedak tabur revlon 43gram</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/62367de657a2c83ff5e97a3dde7b1902.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347206</th>\n",
       "      <td>1756097750</td>\n",
       "      <td>gaun midi bodycon wanita model lengan warna hi...</td>\n",
       "      <td>22</td>\n",
       "      <td>fashion_image/a15e616c290fb142b1a8b217951f765c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294868</th>\n",
       "      <td>1188784503</td>\n",
       "      <td>no.1 family blus sabrina sexy lengan tali moti...</td>\n",
       "      <td>22</td>\n",
       "      <td>fashion_image/c343ed06853c285d85996d5302ccf90e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315964</th>\n",
       "      <td>1223275742</td>\n",
       "      <td>dress v neck lengan pendek casual motif print ...</td>\n",
       "      <td>22</td>\n",
       "      <td>fashion_image/0d8b31d9a649504a66fdbc0ca3b08aad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44794</th>\n",
       "      <td>1629832666</td>\n",
       "      <td>bioaqua blus cushion</td>\n",
       "      <td>2</td>\n",
       "      <td>beauty_image/ec06f3a0fa2c0563f02877287c0f107a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294218</th>\n",
       "      <td>1165060007</td>\n",
       "      <td>gaun wanita model potongan longgar lengan pend...</td>\n",
       "      <td>18</td>\n",
       "      <td>fashion_image/d2033c6032465a9ff3b8cffa298f763c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471465</th>\n",
       "      <td>1791409510</td>\n",
       "      <td>ee womens sheer mesh long sleeve high neck blo...</td>\n",
       "      <td>25</td>\n",
       "      <td>fashion_image/13de20c18de2faa47e94c94478e65e96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474790</th>\n",
       "      <td>1314496206</td>\n",
       "      <td>flow blouse bahan stretch cotton foto asli pro...</td>\n",
       "      <td>26</td>\n",
       "      <td>fashion_image/2a4c0e0696440743a13dd7d5b943faf3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375542</th>\n",
       "      <td>1725021402</td>\n",
       "      <td>dress sexy model v neck lace lengan pendek uku...</td>\n",
       "      <td>22</td>\n",
       "      <td>fashion_image/c8dd83f3f993f18b679ebc05da2f0ca5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254615</th>\n",
       "      <td>1604418669</td>\n",
       "      <td>promo silkygirl magic bb cream 02 radiant spf ...</td>\n",
       "      <td>5</td>\n",
       "      <td>beauty_image/c4f0694e6d84193faa359a180d1cb153.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183152</th>\n",
       "      <td>1600603901</td>\n",
       "      <td>maybelline baby skin instant pink transformer ...</td>\n",
       "      <td>9</td>\n",
       "      <td>beauty_image/fd0fd67fb2b95f2c39c8f06cd10f4bcf.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558483</th>\n",
       "      <td>1812460647</td>\n",
       "      <td>monggo diorder iphone 6s</td>\n",
       "      <td>31</td>\n",
       "      <td>mobile_image/af7047829e497014daa5c2b4914a0fb4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236849</th>\n",
       "      <td>1671016747</td>\n",
       "      <td>promo purbasari alas bedak foundation daily se...</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/054de522277f3a30517e07cc0c0891ed.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406671</th>\n",
       "      <td>869305584</td>\n",
       "      <td>dress sexy bahan lace</td>\n",
       "      <td>21</td>\n",
       "      <td>fashion_image/523e9a2c1bf65e32480dfd2e8780e222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230594</th>\n",
       "      <td>1734297529</td>\n",
       "      <td>termurah peripera ink lasting pink cushion spf...</td>\n",
       "      <td>5</td>\n",
       "      <td>beauty_image/a5941aace7db418a096a1f746958c1c6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588434</th>\n",
       "      <td>46237840</td>\n",
       "      <td>samsung galaxy a3 2015 pearl white</td>\n",
       "      <td>32</td>\n",
       "      <td>mobile_image/69e19dcc475b98436210e28f36d475c3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350736</th>\n",
       "      <td>1281375579</td>\n",
       "      <td>ourlove dress lengan model vintage tali spaghe...</td>\n",
       "      <td>18</td>\n",
       "      <td>fashion_image/67951bf87e551c50b0e3178db308d903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35451</th>\n",
       "      <td>1110871098</td>\n",
       "      <td>harga special kakak sulwhasoo perfecting cushi...</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/c354c4035d22875b9a000edbbe08df5a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658705</th>\n",
       "      <td>1838949047</td>\n",
       "      <td>link adaptor charger mobil samsung dual usb la...</td>\n",
       "      <td>35</td>\n",
       "      <td>mobile_image/290e04d77b793055ba9ac3c4e7758c67.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448958</th>\n",
       "      <td>959689585</td>\n",
       "      <td>sweater kaos wanita neck lengan musim gugur di...</td>\n",
       "      <td>27</td>\n",
       "      <td>fashion_image/e8168584fc316e68db75980a21f6cedd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129918</th>\n",
       "      <td>224128265</td>\n",
       "      <td>city color bb cream</td>\n",
       "      <td>5</td>\n",
       "      <td>beauty_image/8b7262c1057095aad36c48b9634d3590.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80600</th>\n",
       "      <td>1401860320</td>\n",
       "      <td>terbaru innisfree sebum mineral powder emoji g...</td>\n",
       "      <td>3</td>\n",
       "      <td>beauty_image/8b8a5c0b8e6c4dc64a3f725df8ea4285.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158766</th>\n",
       "      <td>1520973410</td>\n",
       "      <td>dijual wardah lightening bb cake powder diskon</td>\n",
       "      <td>5</td>\n",
       "      <td>beauty_image/5b8cfab82d109ead2b9b4a7c13602305.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119498</th>\n",
       "      <td>1742017238</td>\n",
       "      <td>emina bare mineral cushion</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/eef49a22e2208bf9f333600023299c71.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461865</th>\n",
       "      <td>1078070586</td>\n",
       "      <td>bayar tank top neck lengan model backless tali...</td>\n",
       "      <td>28</td>\n",
       "      <td>fashion_image/07dfd1e3022defae2bf8e116f221da96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302453</th>\n",
       "      <td>1495254708</td>\n",
       "      <td>dress wanita lengan pendek model high waist mo...</td>\n",
       "      <td>18</td>\n",
       "      <td>fashion_image/99ffb298002d6abb3b1553e1fa95e0a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517614</th>\n",
       "      <td>948840685</td>\n",
       "      <td>spesial promo beli 2 gratis 1 big sale xiaomi ...</td>\n",
       "      <td>34</td>\n",
       "      <td>mobile_image/1a4943ebcffeb0f5e6eab2ec5b192a17.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347124</th>\n",
       "      <td>1662717404</td>\n",
       "      <td>gaun midi wanita model potongan slim lengan be...</td>\n",
       "      <td>21</td>\n",
       "      <td>fashion_image/ea4668da69e135bfb23ff68f9c0b92d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475634</th>\n",
       "      <td>1475468414</td>\n",
       "      <td>kaos shirt harajuku lengan pendek motif print ...</td>\n",
       "      <td>25</td>\n",
       "      <td>fashion_image/0f99cb4980e68725cabe7cc5c396bdda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661522</th>\n",
       "      <td>1510615314</td>\n",
       "      <td>asus zenfone max pro m1 ram 6 64gb</td>\n",
       "      <td>43</td>\n",
       "      <td>mobile_image/536fbbb9ef98e4373aca47735ab8d4ae.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511554</th>\n",
       "      <td>689328201</td>\n",
       "      <td>iphone 6 plus 64gb seken second gray fulset ca...</td>\n",
       "      <td>35</td>\n",
       "      <td>mobile_image/2243a95f77022bf93bf63b993d813f48.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311528</th>\n",
       "      <td>1153584649</td>\n",
       "      <td>dress mini bodycon v neck wrap silang lengan c...</td>\n",
       "      <td>20</td>\n",
       "      <td>fashion_image/bf586bc5131288273f4a590c8aa6fcc3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571695</th>\n",
       "      <td>756555921</td>\n",
       "      <td>promo cuci gudang ahir tahunk big computer lap...</td>\n",
       "      <td>31</td>\n",
       "      <td>mobile_image/9ce0877574b4531ea95923d32db2a488.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189780</th>\n",
       "      <td>1832354425</td>\n",
       "      <td>cream theraskin flek</td>\n",
       "      <td>4</td>\n",
       "      <td>beauty_image/37e8cddc96cea2af393b4b7e214488e2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509481</th>\n",
       "      <td>343993580</td>\n",
       "      <td>promo apple iphone 7 256 gb jet black garansi ...</td>\n",
       "      <td>35</td>\n",
       "      <td>mobile_image/d83b7e7d0957d3cff703fb03441a87a6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557913</th>\n",
       "      <td>927093949</td>\n",
       "      <td>big promo beli 2 bonus 1 iphone 6 16gb free te...</td>\n",
       "      <td>31</td>\n",
       "      <td>mobile_image/e620f2f41f3543131d775bf25e12bd0b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320667</th>\n",
       "      <td>1811269377</td>\n",
       "      <td>saleseds885 dress pesta bodycon pastel lace br...</td>\n",
       "      <td>18</td>\n",
       "      <td>fashion_image/f86748f6ee71315f2f8b0975e42e0b1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651539</th>\n",
       "      <td>1487236222</td>\n",
       "      <td>oppo a3s 3 32gb purple 36422</td>\n",
       "      <td>34</td>\n",
       "      <td>mobile_image/3894a12a08f3bd0670e6dae6d43a79b8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505474</th>\n",
       "      <td>1465165164</td>\n",
       "      <td>blus wanita v neck lengan aksen lipit warna po...</td>\n",
       "      <td>26</td>\n",
       "      <td>fashion_image/1d396bde83a7ef1639a1059f0c66e4a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459710</th>\n",
       "      <td>1247659054</td>\n",
       "      <td>sq blus v neck lengan sexy model hollow slim f...</td>\n",
       "      <td>25</td>\n",
       "      <td>fashion_image/d29d963c351d34b769e3833822132f3e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21345</th>\n",
       "      <td>1323813216</td>\n",
       "      <td>best seller nature republic soothing moisture ...</td>\n",
       "      <td>5</td>\n",
       "      <td>beauty_image/030a3a20fc9df18e5221468a0784f774.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518319</th>\n",
       "      <td>106562569</td>\n",
       "      <td>samsung galaxy v2 j106 8gb putih</td>\n",
       "      <td>32</td>\n",
       "      <td>mobile_image/39c3bc02f2114bdae3e8fc54ff763728.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94132</th>\n",
       "      <td>64122886</td>\n",
       "      <td>preloved ysl cc cream</td>\n",
       "      <td>5</td>\n",
       "      <td>beauty_image/b59114541a0f0b975fd0bd54ea2c6ab3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629556</th>\n",
       "      <td>1624220223</td>\n",
       "      <td>hot sale promo realme 2 ram 4 64 garansi resmi</td>\n",
       "      <td>35</td>\n",
       "      <td>mobile_image/c0f6df7ba69140efa964e703df895e13.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517958</th>\n",
       "      <td>1415095153</td>\n",
       "      <td>bb aurorra</td>\n",
       "      <td>36</td>\n",
       "      <td>mobile_image/6f7f145ede5392113bbf4407c95fe663.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146749</th>\n",
       "      <td>1110903742</td>\n",
       "      <td>harga special kakak pixy stick foundation</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/cfcd6a8914870bcb117be4bbf0782c60.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437707</th>\n",
       "      <td>1107414703</td>\n",
       "      <td>vooo kaos shirt wanita round neck lengan pende...</td>\n",
       "      <td>25</td>\n",
       "      <td>fashion_image/92595689ab3f57e5d28425355b00c571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73263</th>\n",
       "      <td>1791907070</td>\n",
       "      <td>wardah exclusive liquid foundation 20 ml</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/772817f3a439c7fb536958ccbdd6e650.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508330</th>\n",
       "      <td>45446311</td>\n",
       "      <td>xiaomi mi note ram 3 64gb garansi 1tahun</td>\n",
       "      <td>34</td>\n",
       "      <td>mobile_image/cee54f719507d8f40104b780703c7b19.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543890</th>\n",
       "      <td>1042050565</td>\n",
       "      <td>hot deal baterai batre battery samsung galaxy ...</td>\n",
       "      <td>32</td>\n",
       "      <td>mobile_image/489e368e2cb3901259e934f221e8507f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66227</th>\n",
       "      <td>1219477103</td>\n",
       "      <td>royal jelly radiance foundation broad spectrum...</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/6f9ea326a304db09e704f421a2e5963b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118642</th>\n",
       "      <td>608593618</td>\n",
       "      <td>bb glow crystal cream</td>\n",
       "      <td>5</td>\n",
       "      <td>beauty_image/6bb4df00f9a11ddcaa61df64382ee328.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133323 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            itemid                                              title  \\\n",
       "539829  1058517290                   xiaomi mi a1 garansi resmi 1 tam   \n",
       "473036   286463264                           blus sexy model shoulder   \n",
       "252009  1537965166  best sale jafra royal jelly radiance foundatio...   \n",
       "355772  1465709373  dress midi bodycon casual elegan warna polos p...   \n",
       "553954  1195506745  promo discon samsung galaxy s7 flat sein garan...   \n",
       "620741  1833821649   samsung galaxy a6 plus 2018 new garansi nasional   \n",
       "486345   129360583  kemeja hitam wanita katun adem lengan pendek b...   \n",
       "647884   291297752                                   xiaomi redmi mi5   \n",
       "67883   1633487774                     jd59 bedak tabur revlon 43gram   \n",
       "347206  1756097750  gaun midi bodycon wanita model lengan warna hi...   \n",
       "294868  1188784503  no.1 family blus sabrina sexy lengan tali moti...   \n",
       "315964  1223275742  dress v neck lengan pendek casual motif print ...   \n",
       "44794   1629832666                               bioaqua blus cushion   \n",
       "294218  1165060007  gaun wanita model potongan longgar lengan pend...   \n",
       "471465  1791409510  ee womens sheer mesh long sleeve high neck blo...   \n",
       "474790  1314496206  flow blouse bahan stretch cotton foto asli pro...   \n",
       "375542  1725021402  dress sexy model v neck lace lengan pendek uku...   \n",
       "254615  1604418669  promo silkygirl magic bb cream 02 radiant spf ...   \n",
       "183152  1600603901  maybelline baby skin instant pink transformer ...   \n",
       "558483  1812460647                           monggo diorder iphone 6s   \n",
       "236849  1671016747  promo purbasari alas bedak foundation daily se...   \n",
       "406671   869305584                              dress sexy bahan lace   \n",
       "230594  1734297529  termurah peripera ink lasting pink cushion spf...   \n",
       "588434    46237840                 samsung galaxy a3 2015 pearl white   \n",
       "350736  1281375579  ourlove dress lengan model vintage tali spaghe...   \n",
       "35451   1110871098  harga special kakak sulwhasoo perfecting cushi...   \n",
       "658705  1838949047  link adaptor charger mobil samsung dual usb la...   \n",
       "448958   959689585  sweater kaos wanita neck lengan musim gugur di...   \n",
       "129918   224128265                                city color bb cream   \n",
       "80600   1401860320  terbaru innisfree sebum mineral powder emoji g...   \n",
       "...            ...                                                ...   \n",
       "158766  1520973410     dijual wardah lightening bb cake powder diskon   \n",
       "119498  1742017238                         emina bare mineral cushion   \n",
       "461865  1078070586  bayar tank top neck lengan model backless tali...   \n",
       "302453  1495254708  dress wanita lengan pendek model high waist mo...   \n",
       "517614   948840685  spesial promo beli 2 gratis 1 big sale xiaomi ...   \n",
       "347124  1662717404  gaun midi wanita model potongan slim lengan be...   \n",
       "475634  1475468414  kaos shirt harajuku lengan pendek motif print ...   \n",
       "661522  1510615314                 asus zenfone max pro m1 ram 6 64gb   \n",
       "511554   689328201  iphone 6 plus 64gb seken second gray fulset ca...   \n",
       "311528  1153584649  dress mini bodycon v neck wrap silang lengan c...   \n",
       "571695   756555921  promo cuci gudang ahir tahunk big computer lap...   \n",
       "189780  1832354425                               cream theraskin flek   \n",
       "509481   343993580  promo apple iphone 7 256 gb jet black garansi ...   \n",
       "557913   927093949  big promo beli 2 bonus 1 iphone 6 16gb free te...   \n",
       "320667  1811269377  saleseds885 dress pesta bodycon pastel lace br...   \n",
       "651539  1487236222                       oppo a3s 3 32gb purple 36422   \n",
       "505474  1465165164  blus wanita v neck lengan aksen lipit warna po...   \n",
       "459710  1247659054  sq blus v neck lengan sexy model hollow slim f...   \n",
       "21345   1323813216  best seller nature republic soothing moisture ...   \n",
       "518319   106562569                   samsung galaxy v2 j106 8gb putih   \n",
       "94132     64122886                              preloved ysl cc cream   \n",
       "629556  1624220223     hot sale promo realme 2 ram 4 64 garansi resmi   \n",
       "517958  1415095153                                         bb aurorra   \n",
       "146749  1110903742          harga special kakak pixy stick foundation   \n",
       "437707  1107414703  vooo kaos shirt wanita round neck lengan pende...   \n",
       "73263   1791907070           wardah exclusive liquid foundation 20 ml   \n",
       "508330    45446311           xiaomi mi note ram 3 64gb garansi 1tahun   \n",
       "543890  1042050565  hot deal baterai batre battery samsung galaxy ...   \n",
       "66227   1219477103  royal jelly radiance foundation broad spectrum...   \n",
       "118642   608593618                              bb glow crystal cream   \n",
       "\n",
       "        Category                                         image_path  \n",
       "539829        34  mobile_image/3912586cdf51144db783b2bac1ee4d3f.jpg  \n",
       "473036        26     fashion_image/cb790137111e2525cd895c3375fe84c0  \n",
       "252009         1  beauty_image/5adfe3e65ad2f51a1e67db85a3de8e18.jpg  \n",
       "355772        22     fashion_image/cbedaa2404fb377dc6c271a1081f7baa  \n",
       "553954        35  mobile_image/bb327fec3989b18f714deb3c07203fb8.jpg  \n",
       "620741        35  mobile_image/8959112348969556df29f24d06ecff8f.jpg  \n",
       "486345        27     fashion_image/7a4194bf7b509f29bfc5dcd9cc0355d9  \n",
       "647884        34  mobile_image/8733bba77a727e4771d51b5a8b48c8a5.jpg  \n",
       "67883          3  beauty_image/62367de657a2c83ff5e97a3dde7b1902.jpg  \n",
       "347206        22     fashion_image/a15e616c290fb142b1a8b217951f765c  \n",
       "294868        22     fashion_image/c343ed06853c285d85996d5302ccf90e  \n",
       "315964        22     fashion_image/0d8b31d9a649504a66fdbc0ca3b08aad  \n",
       "44794          2  beauty_image/ec06f3a0fa2c0563f02877287c0f107a.jpg  \n",
       "294218        18     fashion_image/d2033c6032465a9ff3b8cffa298f763c  \n",
       "471465        25     fashion_image/13de20c18de2faa47e94c94478e65e96  \n",
       "474790        26     fashion_image/2a4c0e0696440743a13dd7d5b943faf3  \n",
       "375542        22     fashion_image/c8dd83f3f993f18b679ebc05da2f0ca5  \n",
       "254615         5  beauty_image/c4f0694e6d84193faa359a180d1cb153.jpg  \n",
       "183152         9  beauty_image/fd0fd67fb2b95f2c39c8f06cd10f4bcf.jpg  \n",
       "558483        31  mobile_image/af7047829e497014daa5c2b4914a0fb4.jpg  \n",
       "236849         1  beauty_image/054de522277f3a30517e07cc0c0891ed.jpg  \n",
       "406671        21     fashion_image/523e9a2c1bf65e32480dfd2e8780e222  \n",
       "230594         5  beauty_image/a5941aace7db418a096a1f746958c1c6.jpg  \n",
       "588434        32  mobile_image/69e19dcc475b98436210e28f36d475c3.jpg  \n",
       "350736        18     fashion_image/67951bf87e551c50b0e3178db308d903  \n",
       "35451          3  beauty_image/c354c4035d22875b9a000edbbe08df5a.jpg  \n",
       "658705        35  mobile_image/290e04d77b793055ba9ac3c4e7758c67.jpg  \n",
       "448958        27     fashion_image/e8168584fc316e68db75980a21f6cedd  \n",
       "129918         5  beauty_image/8b7262c1057095aad36c48b9634d3590.jpg  \n",
       "80600          3  beauty_image/8b8a5c0b8e6c4dc64a3f725df8ea4285.jpg  \n",
       "...          ...                                                ...  \n",
       "158766         5  beauty_image/5b8cfab82d109ead2b9b4a7c13602305.jpg  \n",
       "119498         1  beauty_image/eef49a22e2208bf9f333600023299c71.jpg  \n",
       "461865        28     fashion_image/07dfd1e3022defae2bf8e116f221da96  \n",
       "302453        18     fashion_image/99ffb298002d6abb3b1553e1fa95e0a5  \n",
       "517614        34  mobile_image/1a4943ebcffeb0f5e6eab2ec5b192a17.jpg  \n",
       "347124        21     fashion_image/ea4668da69e135bfb23ff68f9c0b92d3  \n",
       "475634        25     fashion_image/0f99cb4980e68725cabe7cc5c396bdda  \n",
       "661522        43  mobile_image/536fbbb9ef98e4373aca47735ab8d4ae.jpg  \n",
       "511554        35  mobile_image/2243a95f77022bf93bf63b993d813f48.jpg  \n",
       "311528        20     fashion_image/bf586bc5131288273f4a590c8aa6fcc3  \n",
       "571695        31  mobile_image/9ce0877574b4531ea95923d32db2a488.jpg  \n",
       "189780         4  beauty_image/37e8cddc96cea2af393b4b7e214488e2.jpg  \n",
       "509481        35  mobile_image/d83b7e7d0957d3cff703fb03441a87a6.jpg  \n",
       "557913        31  mobile_image/e620f2f41f3543131d775bf25e12bd0b.jpg  \n",
       "320667        18     fashion_image/f86748f6ee71315f2f8b0975e42e0b1d  \n",
       "651539        34  mobile_image/3894a12a08f3bd0670e6dae6d43a79b8.jpg  \n",
       "505474        26     fashion_image/1d396bde83a7ef1639a1059f0c66e4a0  \n",
       "459710        25     fashion_image/d29d963c351d34b769e3833822132f3e  \n",
       "21345          5  beauty_image/030a3a20fc9df18e5221468a0784f774.jpg  \n",
       "518319        32  mobile_image/39c3bc02f2114bdae3e8fc54ff763728.jpg  \n",
       "94132          5  beauty_image/b59114541a0f0b975fd0bd54ea2c6ab3.jpg  \n",
       "629556        35  mobile_image/c0f6df7ba69140efa964e703df895e13.jpg  \n",
       "517958        36  mobile_image/6f7f145ede5392113bbf4407c95fe663.jpg  \n",
       "146749         1  beauty_image/cfcd6a8914870bcb117be4bbf0782c60.jpg  \n",
       "437707        25     fashion_image/92595689ab3f57e5d28425355b00c571  \n",
       "73263          1  beauty_image/772817f3a439c7fb536958ccbdd6e650.jpg  \n",
       "508330        34  mobile_image/cee54f719507d8f40104b780703c7b19.jpg  \n",
       "543890        32  mobile_image/489e368e2cb3901259e934f221e8507f.jpg  \n",
       "66227          1  beauty_image/6f9ea326a304db09e704f421a2e5963b.jpg  \n",
       "118642         5  beauty_image/6bb4df00f9a11ddcaa61df64382ee328.jpg  \n",
       "\n",
       "[133323 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to ensemble our best results for training. let's get best results from nlp with count vectorization with optimized C \n",
    "# parameters as well as min_df\n",
    "# This are optimization results for C parameter in logistic regression\n",
    "\n",
    "# params={'model__C':[0.2,0.4,0.8,1,2,4,8]}\n",
    "# {'beauty_': {'model__C': 0.8},\n",
    "#  'mobile_': {'model__C': 1},\n",
    "#  'fashion': {'model__C': 0.4}}\n",
    "\n",
    "# with the corresponding results\n",
    "# {'beauty_': 0.78344144628257784,\n",
    "#  'mobile_': 0.8236574564959771,\n",
    "#  'fashion': 0.6449463364011252}\n",
    "\n",
    "# Also did some optimization for min_df the best results for mobile was 2 otherwise 1.\n",
    "\n",
    "# Let's also check if removing stop words helps to improve model. For the same configuration of optimized parameters\n",
    "\n",
    "# Submit these results and see if it is really improved in leaderboard\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    df=pd.DataFrame(predictions_proba[groups[i]])\n",
    "    df.columns=classes[groups[i]]\n",
    "    df['pred']=df.idxmax(axis=1)\n",
    "    df['itemid']=df_test[df_test.Group==groups[i]].itemid.values\n",
    "    df.to_csv(groups[i]+'_test_proba_nlp_all_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pipe.predict(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70672370657017336"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "\n",
    "for group in groups:\n",
    "    # English vectorization\n",
    "    print('Results for group: ', group)\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(train[train.Group==group].title)\n",
    "    X_test_EN = vectorizerEN.transform(train[train.Group==group].title)\n",
    "    \n",
    "    # Indonesian vectorization\n",
    "    vectorizerID = Word2VecVectorizerID()\n",
    "    X_train_ID = vectorizerID.fit_transform(X_beauty_train)\n",
    "    y_train = train[train.Group==group].Category.values\n",
    "    X_test_ID = vectorizerID.transform(X_beauty_test)\n",
    "    y_test = test[test.Group==group].Category.values\n",
    "    \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    df_test_combined=pd.DataFrame(X_test_EN)\n",
    "    df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    X_test_com=df_test_combined.values\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "81950a0fc37a3ad3df71c78da2d65116e705b5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 1639 / 200608\n",
      "Numer of samples with no words found: 680 / 85975\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "X_train_EN = vectorizerEN.fit_transform(X_beauty_train)\n",
    "#Ytrain = y_beauty_train\n",
    "\n",
    "X_test_EN = vectorizerEN.transform(X_beauty_test)\n",
    "#Ytest = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200608, 300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_EN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 164061 / 200608\n",
      "Numer of samples with no words found: 70373 / 85975\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerID = Word2VecVectorizerID()\n",
    "X_train_ID = vectorizerID.fit_transform(X_beauty_train)\n",
    "y_train = y_beauty_train\n",
    "\n",
    "X_test_ID = vectorizerID.transform(X_beauty_test)\n",
    "y_test = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200608, 300)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=pd.DataFrame(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_combined=pd.DataFrame(X_test_EN)\n",
    "df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200608, 600), (85975, 600))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined.shape,df_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.898877412665\n",
      "test score: 0.730386740331\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(df_train_combined.values,y_train.values)\n",
    "print(\"train score\", model.score(df_train_combined.values,y_train.values))\n",
    "print(\"test score:\", model.score(df_test_combined.values,y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do the same for fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 122720 / 153791\n",
      "Numer of samples with no words found: 52577 / 65911\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerID = Word2VecVectorizerID()\n",
    "X_train_ID = vectorizerID.fit_transform(X_fashion_train)\n",
    "y_train = y_fashion_train\n",
    "\n",
    "X_test_ID = vectorizerID.transform(X_fashion_test)\n",
    "y_test = y_fashion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "_uuid": "81950a0fc37a3ad3df71c78da2d65116e705b5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 144 / 153791\n",
      "Numer of samples with no words found: 68 / 65911\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "X_train_EN = vectorizerEN.fit_transform(X_fashion_train)\n",
    "#Ytrain = y_beauty_train\n",
    "\n",
    "X_test_EN = vectorizerEN.transform(X_fashion_test)\n",
    "#Ytest = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153791, 300)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_EN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153791, 300)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=pd.DataFrame(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_combined=pd.DataFrame(X_test_EN)\n",
    "df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((153791, 600), (65911, 600))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined.shape,df_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.928266283463\n",
      "test score: 0.560968578841\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(df_train_combined.values,y_train.values)\n",
    "print(\"train score\", model.score(df_train_combined.values,y_train.values))\n",
    "print(\"test score:\", model.score(df_test_combined.values,y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "9596b96131b59bf0a17a698bc2f6ea5b15668cdc"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "29fd1d2f87e141770fee8a65e2a6624560748e7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "bcbce333fe04f936ece91eed087caab93e434658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.896150701866\n",
      "test score: 0.731177667927\n"
     ]
    }
   ],
   "source": [
    "print(\"train score\", model.score(Xtrain,Ytrain))\n",
    "print(\"test score:\", model.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "365e103eaacdc5368386b013e8f94ec876bcea31"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "2249fe3559ec3bb5f24db75f6caf7d87462fee14"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "484ae584f6ac8405025c16aa4e561ab414ac755a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40       585\n",
      "           1       0.59      0.76      0.66      6726\n",
      "           2       0.79      0.85      0.82      3282\n",
      "           3       0.88      0.80      0.84     26695\n",
      "           4       0.74      0.61      0.67     15794\n",
      "           5       0.75      0.75      0.75     16427\n",
      "           6       0.33      0.43      0.37       480\n",
      "           7       0.70      0.74      0.72      3265\n",
      "           8       0.51      0.59      0.54      1574\n",
      "           9       0.37      0.72      0.49      1268\n",
      "          10       0.44      0.59      0.50       246\n",
      "          11       0.38      0.55      0.45       849\n",
      "          12       0.85      0.73      0.79      7672\n",
      "          13       0.43      0.63      0.51       588\n",
      "          14       0.14      0.40      0.21       295\n",
      "          15       0.12      0.43      0.19        47\n",
      "          16       0.09      0.34      0.14       182\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     85975\n",
      "   macro avg       0.50      0.62      0.53     85975\n",
      "weighted avg       0.76      0.73      0.74     85975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "14c05cadf20638b9df3d8414b3b462100cc5f370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731177667927\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96f50134c6e4a12fe3e5916bc38b34d27762f45c"
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d30a206a19d8b22e907e82029983f0a669f4ff48"
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdadbef477b40760aaa312b53fc0775e465270f5"
   },
   "outputs": [],
   "source": [
    "#lr.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82c885fc59eaa5a3a557b830f8404b91ab3c7945"
   },
   "outputs": [],
   "source": [
    "#predictions_lr = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5e80f9086701b0cba1af688fb0f487444c93a91"
   },
   "outputs": [],
   "source": [
    "#print(accuracy_score(predictions_lr,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aebf7f17dd57cd6b2584de1e7274ff0758157303"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
