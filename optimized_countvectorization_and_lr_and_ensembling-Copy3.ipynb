{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "20517a3d0aff79fef4251fd889b6e8422900c11b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "059330c4f70d8292575bb5e83a6ad832c7e29041"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9e4bf18683202567e857e8668f09d95100b48d73"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936\n"
     ]
    }
   ],
   "source": [
    "ignore_words = set(stopwords.words('english')).union(set(stopwords.words('indonesian')))\n",
    "print(len(ignore_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "49cac2747c9b75de6a074fd8ecce57b26c1ede31"
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')\n",
    "df_cat=pd.read_json('categories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 nyx sex bomb pallete natural palette\n",
       "1    etude house precious mineral any cushion pearl...\n",
       "2                             milani rose powder blush\n",
       "3                  etude house baby sweet sugar powder\n",
       "4         bedak revlon color stay aqua mineral make up\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.title.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train['Group']=df_train.image_path.map(lambda x: x[:7])\n",
    "df_test['Group']=df_test.image_path.map(lambda x: x[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "509be9648ff1ececf1eed491d130429695a62748"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(df_train,random_state=2019,stratify=df_train.Category,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=['beauty_','mobile_','fashion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some linear models\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "\n",
    "# SCM for classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build pipeline for parameter search in n_grams and and various models\n",
    "lr=LogisticRegression()\n",
    "nb=MultinomialNB()\n",
    "svc=SVC()\n",
    "# let's check first three and see which one is best\n",
    "gnb=GaussianNB()\n",
    "bnb=BernoulliNB()\n",
    "br=BayesianRidge()\n",
    "rf=RandomForestClassifier(n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best cv scores for parameter for lr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(name,dic):\n",
    "    df_sub=df_test.copy()\n",
    "    for group in dic.keys():\n",
    "        df_sub.loc[df_sub.Group==group,'Category']=dic[group]\n",
    "    df_sub.loc[:,'Category']=df_sub.Category.astype('int')\n",
    "    df_sub[['itemid','Category']].to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do ensembling now! \n",
    "## So we have results from:\n",
    "## 1) CountVectorization with logistic regression : lr ending\n",
    "## 2) CountVectorization with Naive Bayes:  nb ending\n",
    "## 3) Image categorization:  im ending\n",
    "## 4) word2vec predictions: w2v ending\n",
    "\n",
    "\n",
    "## 1 and 2 might be highly correlated with each other. I might remove Naive Bayes. But we also can try with and without and observe results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr={}\n",
    "for i in range(3):\n",
    "    val_test=[]\n",
    "    df1=pd.read_csv(groups[i]+'_test_proba_nlp_val_data2.csv')\n",
    "    df2=pd.read_csv(groups[i]+'_test_proba_nlp_all_data2.csv')\n",
    "    val_test.append(df1)\n",
    "    val_test.append(df2)\n",
    "    df_lr[groups[i]]=val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own corpus in word2vec unlike original of this code\n",
    "df_w2v={}\n",
    "for i in range(3):\n",
    "    val_test=[]\n",
    "    df1=pd.read_csv(groups[i]+'_test_proba_w2v_own_val_data.csv')\n",
    "    df2=pd.read_csv(groups[i]+'_test_proba_w2v_own_all_data.csv')\n",
    "    val_test.append(df1)\n",
    "    val_test.append(df2)\n",
    "    df_w2v[groups[i]]=val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb={}\n",
    "for i in range(3):\n",
    "    val_test=[]\n",
    "    df1=pd.read_csv(groups[i]+'_val_proba_nlp_nb.csv')\n",
    "    df2=pd.read_csv(groups[i]+'_test_proba_nlp_nb.csv')\n",
    "    val_test.append(df1)\n",
    "    val_test.append(df2)\n",
    "    df_nb[groups[i]]=val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have previously ordered outputof image predictions so we can just upload all of them\n",
    "df_im={}\n",
    "for group in groups:\n",
    "    if group=='mobile_':\n",
    "        val_test=[]\n",
    "        df1=pd.read_csv(group+'_val_im.csv') \n",
    "        df2=pd.read_csv(group+'_test_im.csv') \n",
    "        val_test.append(df1)\n",
    "        val_test.append(df2)\n",
    "        df_im[group]=val_test # Overite df_im but I use df_im in the rest of the code\n",
    "    elif group=='fashion':\n",
    "        val_test=[]\n",
    "        df1=pd.read_csv('val_fashion_v2.csv') \n",
    "        df2=pd.read_csv('test_all_fashion_v2.csv') # trained on 80% of data\n",
    "        val_test.append(df1)\n",
    "        val_test.append(df2)\n",
    "        df_im[group]=val_test # Overite df_im but I use df_im in the rest of the code\n",
    "    else:\n",
    "        val_test=[]\n",
    "        df1=pd.read_csv('val_beauty__v2.csv') \n",
    "        df2=pd.read_csv('test_beauty__v2.csv') # trained on 80% of data\n",
    "        val_test.append(df1)\n",
    "        val_test.append(df2)\n",
    "        df_im[group]=val_test # Overite df_im but I use df_im in the rest of the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to check impact of fashion image classification improvement on predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finally, we can start ensembling. Let's first check their relative error in internal test set. Also, correlations btw them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[df_lr,df_nb,df_w2v,df_im]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define columns for each category\n",
    "columns={}\n",
    "columns['beauty_']=[str(i) for i in range(17)]\n",
    "columns['mobile_']=[str(i) for i in range(31,58)]\n",
    "columns['fashion']=[str(i) for i in range(17,31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_im is actually df_im2 we overwrite it in the above code\n",
    "models={'lr':df_lr,'nb':df_nb,'w2v':df_w2v,'im':df_im}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for model:  lr\n",
      "beauty_ 0.789800582724\n",
      "mobile_ 0.830687665679\n",
      "fashion 0.652056166223\n",
      "Accuracy score for model:  nb\n",
      "beauty_ 0.764188635134\n",
      "mobile_ 0.778949009824\n",
      "fashion 0.592362486061\n",
      "Accuracy score for model:  w2v\n",
      "beauty_ 0.752324790202\n",
      "mobile_ 0.776360517698\n",
      "fashion 0.601351812658\n",
      "Accuracy score for model:  im\n",
      "beauty_ 0.69837918942\n",
      "mobile_ 0.562763137377\n",
      "fashion 0.525727680299\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    if name=='im':\n",
    "        pred='final_pred'\n",
    "    else:\n",
    "        pred='pred'\n",
    "    print('Accuracy score for model: ', name)\n",
    "    for group in groups:\n",
    "        print(group,accuracy_score(test[test.Group==group].Category,model[group][0][pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous results of word2vec based on combination of english and indonesian corpuses\n",
    "Our own word2vec seems to be much better in all of groups\n",
    "\n",
    "Accuracy score for model:  w2v\n",
    "beauty_ 0.744054992411\n",
    "mobile_ 0.766505535631\n",
    "fashion 0.579777428825\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all={}\n",
    "for group in groups:\n",
    "    val_test=[pd.DataFrame(),pd.DataFrame()]\n",
    "    df_all[group]=val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's put all of the predictions together for ensembling\n",
    "# I am still not sure about best stragery for ensembling\n",
    "df_all_val={}\n",
    "df_all_test={}\n",
    "for group in groups:\n",
    "    df_all_val[group]=models['lr'][group][0][columns[group]].copy()\n",
    "    df_all_test[group]=models['lr'][group][1][columns[group]].copy()\n",
    "    for name, model in models.items():\n",
    "        if name!='lr':\n",
    "            df1=models[name][group][0][columns[group]].copy()\n",
    "            df_all_val[group]=df_all_val[group].join(df1,rsuffix=name)\n",
    "            \n",
    "            df2=models[name][group][1][columns[group]].copy()\n",
    "            df_all_test[group]=df_all_test[group].join(df2,rsuffix=name)\n",
    "        \n",
    "# Now we put everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df_all_val and test beauty_\n",
      "(57317, 68) (57317, 5)\n",
      "shape of df_all_val and test mobile_\n",
      "(32065, 108) (32065, 5)\n",
      "shape of df_all_val and test fashion\n",
      "(43941, 56) (43941, 5)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "for group in groups:\n",
    "    print(\"shape of df_all_val and test\", group)\n",
    "    print(df_all_val[group].shape, test[test.Group==group].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df_all_test and df_test beauty_\n",
      "(76545, 68) (76545, 4)\n",
      "shape of df_all_test and df_test mobile_\n",
      "(40417, 108) (40417, 4)\n",
      "shape of df_all_test and df_test fashion\n",
      "(55440, 56) (55440, 4)\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    print(\"shape of df_all_test and df_test\", group)\n",
    "    print(df_all_test[group].shape, df_test[df_test.Group==group].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "svm=SVC(kernel='linear')\n",
    "rf=RandomForestClassifier(n_estimators=200)\n",
    "knn=KNeighborsClassifier(n_neighbors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_en2={}\n",
    "for group in groups:\n",
    "    pipe_en2[group]=Pipeline([('model',rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_en2['beauty_']=RandomForestClassifier(n_estimators=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=280, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_en2['beauty_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am not sure but we might be overfitting. Let's try our previous approach\n",
    "\n",
    "\n",
    "def eval_model():\n",
    "    folds=StratifiedKFold(n_splits=5,shuffle=True,random_state=2019)\n",
    "    predictions2={}\n",
    "    for group in ['beauty_']:\n",
    "        print(\"Results for group\", group)\n",
    "        oof=np.zeros(len(df_all_val[group]))\n",
    "        pred=np.zeros((len(df_test[df_test.Group==group]),folds.n_splits))\n",
    "        X=df_all_val[group].values\n",
    "        y=test[test.Group==group].Category.values\n",
    "        X_sub=df_all_test[group].values\n",
    "        model=pipe_en2[group]\n",
    "        for fold_,(trn_idx,val_idx) in enumerate(folds.split(X,y)):\n",
    "            print(\"Fold:\",fold_)\n",
    "            X_train=X[trn_idx]\n",
    "            y_train=y[trn_idx]\n",
    "            model.fit(X_train,y_train)\n",
    "            X_val=X[val_idx]\n",
    "            oof[val_idx]=model.predict(X_val)\n",
    "            pred[:,fold_]=model.predict(X_sub)\n",
    "            print('Acuracy of fold:',accuracy_score(y[val_idx],oof[val_idx]))\n",
    "        print('Acuracy of overall:',accuracy_score(y,oof))\n",
    "        predictions2[group]=pred\n",
    "    return predictions2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for group beauty_\n",
      "Fold: 0\n",
      "Acuracy of fold: 0.790496948561\n",
      "Fold: 1\n",
      "Acuracy of fold: 0.789271696468\n",
      "Fold: 2\n",
      "Acuracy of fold: 0.799703393527\n",
      "Fold: 3\n",
      "Acuracy of fold: 0.794189495725\n",
      "Fold: 4\n",
      "Acuracy of fold: 0.789560967094\n",
      "Acuracy of overall: 0.792644416142\n"
     ]
    }
   ],
   "source": [
    "pred=eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2={}\n",
    "for group in ['beauty_']:\n",
    "    predictions2[group]=pd.DataFrame(pred[group]).mode(axis=1)[0].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76545, 4) (76545,)\n"
     ]
    }
   ],
   "source": [
    "for group in ['beauty_']:\n",
    "    print(df_test[df_test.Group==group].shape,predictions2[group].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370855998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637234604</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690282890</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930913462</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039280071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid  Category\n",
       "0   370855998         5\n",
       "1   637234604         5\n",
       "2   690282890         5\n",
       "3   930913462         5\n",
       "4  1039280071         5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub=pd.read_csv('ensemble_4_v1.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['Group']=df_test['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beauty_\n"
     ]
    }
   ],
   "source": [
    "# LB:0.76579. Here we use image classification model which is trained to 99.5% of dataset.\n",
    "# Previous score: LB:0.76473  just slightly better than previous\n",
    "for group in ['beauty_']:\n",
    "    print(group)\n",
    "    df_sub.loc[df_sub.Group==group,'Category']=predictions2[group]\n",
    "del df_sub['Group']\n",
    "df_sub.to_csv('ensemble_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's use model trained for all data set\n",
    "df_im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28',\n",
       "       '29', '30', '17nb', '18nb', '19nb', '20nb', '21nb', '22nb', '23nb',\n",
       "       '24nb', '25nb', '26nb', '27nb', '28nb', '29nb', '30nb', '17w2v',\n",
       "       '18w2v', '19w2v', '20w2v', '21w2v', '22w2v', '23w2v', '24w2v', '25w2v',\n",
       "       '26w2v', '27w2v', '28w2v', '29w2v', '30w2v', '17im', '18im', '19im',\n",
       "       '20im', '21im', '22im', '23im', '24im', '25im', '26im', '27im', '28im',\n",
       "       '29im', '30im'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_test['fashion'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am not sure but we might be overfitting. Let's try our previous approach\n",
    "\n",
    "\n",
    "def eval_model():\n",
    "    folds=StratifiedKFold(n_splits=5,shuffle=True,random_state=2019)\n",
    "    predictions2={}\n",
    "    for group in ['fashion']:\n",
    "        print(\"Results for group\", group)\n",
    "        oof=np.zeros(len(df_all_val[group]))\n",
    "        pred=np.zeros((len(df_test[df_test.Group==group]),folds.n_splits))\n",
    "        X=df_all_val[group].values\n",
    "        y=test[test.Group==group].Category.values\n",
    "        X_sub=df_all_test[group].values\n",
    "        model=pipe_en2[group]\n",
    "        for fold_,(trn_idx,val_idx) in enumerate(folds.split(X,y)):\n",
    "            print(\"Fold:\",fold_)\n",
    "            X_train=X[trn_idx]\n",
    "            y_train=y[trn_idx]\n",
    "            model.fit(X_train,y_train)\n",
    "            X_val=X[val_idx]\n",
    "            oof[val_idx]=model.predict(X_val)\n",
    "            pred[:,fold_]=model.predict(X_sub)\n",
    "            print('Acuracy of fold:',accuracy_score(y[val_idx],oof[val_idx]))\n",
    "        print('Acuracy of overall:',accuracy_score(y,oof))\n",
    "        predictions2[group]=pred\n",
    "    return predictions2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for group fashion\n",
      "Fold: 0\n",
      "Acuracy of fold: 0.6748180163785259\n",
      "Fold: 1\n",
      "Acuracy of fold: 0.6719372085087021\n",
      "Fold: 2\n",
      "Acuracy of fold: 0.6698521046643914\n",
      "Fold: 3\n",
      "Acuracy of fold: 0.6663252532149767\n",
      "Fold: 4\n",
      "Acuracy of fold: 0.6589226739551304\n",
      "Acuracy of overall: 0.6683735008306593\n"
     ]
    }
   ],
   "source": [
    "pred=eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2={}\n",
    "for group in ['fashion']:\n",
    "    predictions2[group]=pd.DataFrame(pred[group]).mode(axis=1)[0].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55440, 4) (55440,)\n"
     ]
    }
   ],
   "source": [
    "for group in ['fashion']:\n",
    "    print(df_test[df_test.Group==group].shape,predictions2[group].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370855998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637234604</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690282890</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930913462</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039280071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid  Category\n",
       "0   370855998         5\n",
       "1   637234604         5\n",
       "2   690282890         5\n",
       "3   930913462         5\n",
       "4  1039280071         5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub=pd.read_csv('ensemble_3_v2.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['Group']=df_test['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion\n"
     ]
    }
   ],
   "source": [
    "#LB:0.76473\n",
    "# Previous score: LB:0.76428  just slightly better than previous\n",
    "for group in ['fashion']:\n",
    "    print(group)\n",
    "    df_sub.loc[df_sub.Group==group,'Category']=predictions2[group]\n",
    "del df_sub['Group']\n",
    "df_sub.to_csv('ensemble_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have previously ordered outputof image predictions so we can just upload all of them\n",
    "df_im1={}\n",
    "for group in groups:\n",
    "    if group!='fashion':\n",
    "        val_test=[]\n",
    "        df1=pd.read_csv(group+'_val_im.csv') \n",
    "        df2=pd.read_csv(group+'_test_im.csv') \n",
    "        val_test.append(df1)\n",
    "        val_test.append(df2)\n",
    "        df_im1[group]=val_test\n",
    "    else:\n",
    "        val_test=[]\n",
    "        df1=pd.read_csv('val_fashion_v2.csv') \n",
    "        df2=pd.read_csv('test_fashion_v2.csv') # trained on 80% of data\n",
    "        val_test.append(df1)\n",
    "        val_test.append(df2)\n",
    "        df_im1[group]=val_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_im2={}\n",
    "for group in groups:\n",
    "    if group!='fashion':\n",
    "        val_test=[]\n",
    "        df1=pd.read_csv(group+'_val_im.csv') \n",
    "        df2=pd.read_csv(group+'_test_im.csv') \n",
    "        val_test.append(df1)\n",
    "        val_test.append(df2)\n",
    "        df_im2[group]=val_test\n",
    "    else:\n",
    "        val_test=[]\n",
    "        df1=pd.read_csv('val_fashion_v2.csv') \n",
    "        df2=pd.read_csv('test_all_fashion_v2.csv') # Trained on 99.5% of data\n",
    "        val_test.append(df1)\n",
    "        val_test.append(df2)\n",
    "        df_im2[group]=val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[df_lr,df_nb,df_w2v,df_im1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define columns for each category\n",
    "columns={}\n",
    "columns['beauty_']=[str(i) for i in range(17)]\n",
    "columns['mobile_']=[str(i) for i in range(31,58)]\n",
    "columns['fashion']=[str(i) for i in range(17,31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_im is actually df_im2 we overwrite it in the above code\n",
    "models={'lr':df_lr,'nb':df_nb,'w2v':df_w2v,'im':df_im1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for model:  lr\n",
      "beauty_ 0.7898005827241481\n",
      "mobile_ 0.8306876656790894\n",
      "fashion 0.6520561662228898\n",
      "Accuracy score for model:  nb\n",
      "beauty_ 0.7641886351344278\n",
      "mobile_ 0.7789490098237954\n",
      "fashion 0.5923624860608543\n",
      "Accuracy score for model:  w2v\n",
      "beauty_ 0.7523247902018598\n",
      "mobile_ 0.7763605176984251\n",
      "fashion 0.6013518126578822\n",
      "Accuracy score for model:  im\n",
      "beauty_ 0.6406476263586719\n",
      "mobile_ 0.5627631373772025\n",
      "fashion 0.5257276802985822\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    if name=='im':\n",
    "        pred='final_pred'\n",
    "    else:\n",
    "        pred='pred'\n",
    "    print('Accuracy score for model: ', name)\n",
    "    for group in groups:\n",
    "        print(group,accuracy_score(test[test.Group==group].Category,model[group][0][pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous results of word2vec based on combination of english and indonesian corpuses\n",
    "Our own word2vec seems to be much better in all of groups\n",
    "\n",
    "Accuracy score for model:  w2v\n",
    "beauty_ 0.744054992411\n",
    "mobile_ 0.766505535631\n",
    "fashion 0.579777428825\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all={}\n",
    "for group in groups:\n",
    "    val_test=[pd.DataFrame(),pd.DataFrame()]\n",
    "    df_all[group]=val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's put all of the predictions together for ensembling\n",
    "# I am still not sure about best stragery for ensembling\n",
    "df_all_val={}\n",
    "df_all_test={}\n",
    "for group in groups:\n",
    "    df_all_val[group]=models['lr'][group][0][columns[group]].copy()\n",
    "    df_all_test[group]=models['lr'][group][1][columns[group]].copy()\n",
    "    for name, model in models.items():\n",
    "        if name!='lr':\n",
    "            df1=models[name][group][0][columns[group]].copy()\n",
    "            df_all_val[group]=df_all_val[group].join(df1,rsuffix=name)\n",
    "            \n",
    "            df2=models[name][group][1][columns[group]].copy()\n",
    "            df_all_test[group]=df_all_test[group].join(df2,rsuffix=name)\n",
    "        \n",
    "# Now we put everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for group fashion\n",
      "Fold: 0\n",
      "Acuracy of fold: 0.6770928116469518\n",
      "Fold: 1\n",
      "Acuracy of fold: 0.6709134341940621\n",
      "Fold: 2\n",
      "Acuracy of fold: 0.6690557451649601\n",
      "Fold: 3\n",
      "Acuracy of fold: 0.6659838397632867\n",
      "Fold: 4\n",
      "Acuracy of fold: 0.660289260904225\n",
      "Acuracy of overall: 0.6686693520857514\n"
     ]
    }
   ],
   "source": [
    "pred=eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2={}\n",
    "for group in ['fashion']:\n",
    "    predictions2[group]=pd.DataFrame(pred[group]).mode(axis=1)[0].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55440, 4) (55440,)\n"
     ]
    }
   ],
   "source": [
    "for group in ['fashion']:\n",
    "    print(df_test[df_test.Group==group].shape,predictions2[group].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370855998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637234604</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690282890</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930913462</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039280071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid  Category\n",
       "0   370855998         5\n",
       "1   637234604         5\n",
       "2   690282890         5\n",
       "3   930913462         5\n",
       "4  1039280071         5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub=pd.read_csv('ensemble_3_v2.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['Group']=df_test['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion\n"
     ]
    }
   ],
   "source": [
    "#LB:0.0.76542 which is lower than previous results. Cuz images was trained to all data\n",
    "\n",
    "for group in ['fashion']:\n",
    "    print(group)\n",
    "    df_sub.loc[df_sub.Group==group,'Category']=predictions2[group]\n",
    "del df_sub['Group']\n",
    "df_sub.to_csv('ensemble_4_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_en=Pipeline([('model',lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous function to evaluate model for beauty products\n",
    "def eval_model_tr(model):\n",
    "    y=df_beauty_val.Category\n",
    "    folds=StratifiedKFold(n_splits=5,shuffle=True,random_state=2019)\n",
    "    oof=np.zeros(len(df_all_prob))\n",
    "    # prediction for the model with 80 of data\n",
    "#     pred_80=np.zeros((len(X_test_beauty1),folds.n_splits))\n",
    "    #prediction for the model with 100 of data\n",
    "#     pred_100=np.zeros((len(X_test_beauty2),folds.n_splits))\n",
    "\n",
    "    for fold_,(trn_idx,val_idx) in enumerate(folds.split(df_all_prob,y)):\n",
    "#         print(\"Fold:\",fold_)\n",
    "        X_train=df_all_prob.loc[trn_idx,:]\n",
    "        y_train=y[trn_idx]\n",
    "        model.fit(X_train,y_train)\n",
    "        X_val=df_all_prob.loc[val_idx,:]\n",
    "        oof[val_idx]=model.predict(X_val)\n",
    "#         pred_80[:,fold_]=model.predict(X_test_beauty1)\n",
    "#         pred_100[:,fold_]=model.predict(X_test_beauty2)\n",
    "#         print('Acuracy of fold:',accuracy_score(y[val_idx],oof[val_idx]))\n",
    "    print('Acuracy of overall:',accuracy_score(y,oof))\n",
    "    return accuracy_score(y,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>index</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>final_pred</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [itemid, index, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, final_pred, Category]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df,df_im['fashion'][0],on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>index</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>final_pred</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1058517290</td>\n",
       "      <td>3912586cdf51144db783b2bac1ee4d3f.jpg</td>\n",
       "      <td>0.026980</td>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.407791</td>\n",
       "      <td>0.372147</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1195506745</td>\n",
       "      <td>bb327fec3989b18f714deb3c07203fb8.jpg</td>\n",
       "      <td>0.072345</td>\n",
       "      <td>0.246230</td>\n",
       "      <td>0.057411</td>\n",
       "      <td>0.097349</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.079219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1833821649</td>\n",
       "      <td>8959112348969556df29f24d06ecff8f.jpg</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.167811</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>0.275278</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291297752</td>\n",
       "      <td>8733bba77a727e4771d51b5a8b48c8a5.jpg</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.116616</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812460647</td>\n",
       "      <td>af7047829e497014daa5c2b4914a0fb4.jpg</td>\n",
       "      <td>0.872700</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>0.066922</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid                                 index        31        32  \\\n",
       "0  1058517290  3912586cdf51144db783b2bac1ee4d3f.jpg  0.026980  0.020451   \n",
       "1  1195506745  bb327fec3989b18f714deb3c07203fb8.jpg  0.072345  0.246230   \n",
       "2  1833821649  8959112348969556df29f24d06ecff8f.jpg  0.092200  0.167811   \n",
       "3   291297752  8733bba77a727e4771d51b5a8b48c8a5.jpg  0.043451  0.026404   \n",
       "4  1812460647  af7047829e497014daa5c2b4914a0fb4.jpg  0.872700  0.008431   \n",
       "\n",
       "         33        34        35        36        37        38    ...     \\\n",
       "0  0.004094  0.407791  0.372147  0.000012  0.001650  0.001870    ...      \n",
       "1  0.057411  0.097349  0.273988  0.002055  0.027128  0.079219    ...      \n",
       "2  0.000182  0.012845  0.275278  0.000306  0.001374  0.000576    ...      \n",
       "3  0.017773  0.651762  0.116616  0.000137  0.004889  0.001703    ...      \n",
       "4  0.000067  0.021418  0.066922  0.000281  0.000757  0.000065    ...      \n",
       "\n",
       "         50        51        52        53        54        55        56  \\\n",
       "0  0.005001  0.000660  0.001180  0.000943  0.000728  0.000967  0.000833   \n",
       "1  0.000813  0.000252  0.000367  0.000301  0.000122  0.001252  0.000214   \n",
       "2  0.000136  0.002763  0.001903  0.000443  0.007212  0.000416  0.000406   \n",
       "3  0.000309  0.000054  0.000225  0.000511  0.000033  0.000112  0.000249   \n",
       "4  0.000005  0.000052  0.000018  0.000056  0.000236  0.000021  0.000038   \n",
       "\n",
       "         57  final_pred  Category  \n",
       "0  0.000563          34        34  \n",
       "1  0.000445          35        35  \n",
       "2  0.000569          42        35  \n",
       "3  0.000087          34        34  \n",
       "4  0.000015          31        31  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check if it works\n",
    "df_im['mobile_'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>Category</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Group</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506285</th>\n",
       "      <td>2346660</td>\n",
       "      <td>apple iphone 4s back glass spare part original...</td>\n",
       "      <td>31</td>\n",
       "      <td>mobile_image/a9c8f0fdd6587deed197634066cf7eee.jpg</td>\n",
       "      <td>mobile_</td>\n",
       "      <td>a9c8f0fdd6587deed197634066cf7eee.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506286</th>\n",
       "      <td>2816338</td>\n",
       "      <td>iphone 4s 64gb white</td>\n",
       "      <td>31</td>\n",
       "      <td>mobile_image/3b9a11608551b11b9330268e0d055e01.jpg</td>\n",
       "      <td>mobile_</td>\n",
       "      <td>3b9a11608551b11b9330268e0d055e01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506287</th>\n",
       "      <td>2847602</td>\n",
       "      <td>samsung sm b310e piton dual sim</td>\n",
       "      <td>32</td>\n",
       "      <td>mobile_image/1d719e936841a83c165da620f927de68.jpg</td>\n",
       "      <td>mobile_</td>\n",
       "      <td>1d719e936841a83c165da620f927de68.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506288</th>\n",
       "      <td>3116949</td>\n",
       "      <td>samsung caramel gt e1272 dual sim 32 mb putih</td>\n",
       "      <td>32</td>\n",
       "      <td>mobile_image/1d35a74d90df6cf4a02e6a5df9e9ff29.jpg</td>\n",
       "      <td>mobile_</td>\n",
       "      <td>1d35a74d90df6cf4a02e6a5df9e9ff29.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506289</th>\n",
       "      <td>3794648</td>\n",
       "      <td>garskin sony experia z z1 z2 ultra</td>\n",
       "      <td>33</td>\n",
       "      <td>mobile_image/5556577b09539a9c0db0d00e0f171e2d.jpg</td>\n",
       "      <td>mobile_</td>\n",
       "      <td>5556577b09539a9c0db0d00e0f171e2d.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         itemid                                              title  Category  \\\n",
       "506285  2346660  apple iphone 4s back glass spare part original...        31   \n",
       "506286  2816338                               iphone 4s 64gb white        31   \n",
       "506287  2847602                    samsung sm b310e piton dual sim        32   \n",
       "506288  3116949      samsung caramel gt e1272 dual sim 32 mb putih        32   \n",
       "506289  3794648                 garskin sony experia z z1 z2 ultra        33   \n",
       "\n",
       "                                               image_path    Group  \\\n",
       "506285  mobile_image/a9c8f0fdd6587deed197634066cf7eee.jpg  mobile_   \n",
       "506286  mobile_image/3b9a11608551b11b9330268e0d055e01.jpg  mobile_   \n",
       "506287  mobile_image/1d719e936841a83c165da620f927de68.jpg  mobile_   \n",
       "506288  mobile_image/1d35a74d90df6cf4a02e6a5df9e9ff29.jpg  mobile_   \n",
       "506289  mobile_image/5556577b09539a9c0db0d00e0f171e2d.jpg  mobile_   \n",
       "\n",
       "                                       index  \n",
       "506285  a9c8f0fdd6587deed197634066cf7eee.jpg  \n",
       "506286  3b9a11608551b11b9330268e0d055e01.jpg  \n",
       "506287  1d719e936841a83c165da620f927de68.jpg  \n",
       "506288  1d35a74d90df6cf4a02e6a5df9e9ff29.jpg  \n",
       "506289  5556577b09539a9c0db0d00e0f171e2d.jpg  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.Group=='mobile_'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>index</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>final_pred</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2816338</td>\n",
       "      <td>3b9a11608551b11b9330268e0d055e01.jpg</td>\n",
       "      <td>0.883424</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.016350</td>\n",
       "      <td>0.073758</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>2.546633e-05</td>\n",
       "      <td>1.471064e-05</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1.323019e-05</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9503620</td>\n",
       "      <td>a23f0381039e5595559be27db3271d2f.jpg</td>\n",
       "      <td>0.278721</td>\n",
       "      <td>0.177533</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.070696</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>...</td>\n",
       "      <td>3.675401e-04</td>\n",
       "      <td>1.966892e-04</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>1.328025e-04</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26702291</td>\n",
       "      <td>2c0ea46a95837e5171bd43512e82b1ce.jpg</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.978527</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>2.433453e-07</td>\n",
       "      <td>1.700982e-06</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.335207e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74050515</td>\n",
       "      <td>9a28a64c29e97e52c71ed45b029281ec.jpg</td>\n",
       "      <td>0.601693</td>\n",
       "      <td>0.033724</td>\n",
       "      <td>0.028193</td>\n",
       "      <td>0.028183</td>\n",
       "      <td>0.180513</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531332e-03</td>\n",
       "      <td>1.450678e-04</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>3.438597e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122874123</td>\n",
       "      <td>3cfd98eb1f103623e12b8f081d702a66.jpg</td>\n",
       "      <td>0.048917</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.500844</td>\n",
       "      <td>0.248733</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>...</td>\n",
       "      <td>7.084288e-05</td>\n",
       "      <td>2.756204e-05</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>1.623501e-04</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>148667803</td>\n",
       "      <td>083faffd864dd1e6aff8cbc892ac15d7.jpg</td>\n",
       "      <td>0.623251</td>\n",
       "      <td>0.154122</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.039050</td>\n",
       "      <td>0.051524</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371836e-05</td>\n",
       "      <td>4.439028e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>3.032195e-05</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193655696</td>\n",
       "      <td>c1b8da227c7d1d4a4edd84496e914771.jpg</td>\n",
       "      <td>0.030702</td>\n",
       "      <td>0.029294</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>0.802044</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>...</td>\n",
       "      <td>7.922183e-04</td>\n",
       "      <td>1.047876e-04</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>1.658877e-04</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>210801578</td>\n",
       "      <td>f14091a8b8a09cd6b5e64b6ae2b45185.jpg</td>\n",
       "      <td>0.277034</td>\n",
       "      <td>0.214561</td>\n",
       "      <td>0.084110</td>\n",
       "      <td>0.074292</td>\n",
       "      <td>0.241911</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.019214</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>...</td>\n",
       "      <td>8.234581e-05</td>\n",
       "      <td>8.576331e-05</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>1.556106e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>212660404</td>\n",
       "      <td>39ed4573ea35e9b4e4619f37734c512a.jpg</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.899937</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>0.026526</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121018e-05</td>\n",
       "      <td>4.890963e-04</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>5.743321e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>213418407</td>\n",
       "      <td>d961511fb22ca5eec825219035c0e1d4.jpg</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.458902</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.233880</td>\n",
       "      <td>0.271702</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>...</td>\n",
       "      <td>3.200407e-05</td>\n",
       "      <td>4.720400e-04</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>8.762698e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>224567557</td>\n",
       "      <td>b1578dd4fea374e77138f9a933b8d73c.jpg</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.332045</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.295736</td>\n",
       "      <td>0.021220</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>0.021355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.802436e-03</td>\n",
       "      <td>3.505952e-04</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>6.480849e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>257562289</td>\n",
       "      <td>b557939f68ad26ddde7012a5fd854560.jpg</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.035738</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.072940</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>...</td>\n",
       "      <td>5.979235e-06</td>\n",
       "      <td>1.858851e-04</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>1.615911e-05</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>269996732</td>\n",
       "      <td>d67af08316609b9b66e63da4e4c26034.jpg</td>\n",
       "      <td>0.077402</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.483558</td>\n",
       "      <td>0.063054</td>\n",
       "      <td>0.129270</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.249744e-04</td>\n",
       "      <td>4.856712e-05</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>1.212007e-04</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>270365319</td>\n",
       "      <td>b0bdaf97069f7b09c2332d0fb0de56e9.jpg</td>\n",
       "      <td>0.223796</td>\n",
       "      <td>0.204085</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.116897</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>...</td>\n",
       "      <td>2.191225e-04</td>\n",
       "      <td>4.023139e-04</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>3.163820e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>279946181</td>\n",
       "      <td>4540b00617a6a9f484e8c9141ff2333a.jpg</td>\n",
       "      <td>0.564261</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.028366</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>1.093048e-04</td>\n",
       "      <td>3.789398e-05</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>5.387356e-05</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>283137033</td>\n",
       "      <td>27a70936648c2ec958cbf7bf96e650c8.jpg</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.045256</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990368e-03</td>\n",
       "      <td>1.785333e-04</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>1.444049e-03</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>287953674</td>\n",
       "      <td>7436a65bb4ebfca250eee6bdbc0d8094.jpg</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.021487</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>3.638710e-05</td>\n",
       "      <td>8.756408e-05</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.077856e-04</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>290669247</td>\n",
       "      <td>21f4a6682d77fa308b453ce8b71175d8.jpg</td>\n",
       "      <td>0.137716</td>\n",
       "      <td>0.510536</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.064764</td>\n",
       "      <td>0.120508</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>...</td>\n",
       "      <td>3.095026e-05</td>\n",
       "      <td>9.943701e-05</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>5.831746e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>301704723</td>\n",
       "      <td>932d462d21c2f5afdcc98219c8a09cb7.jpg</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>...</td>\n",
       "      <td>3.369434e-07</td>\n",
       "      <td>1.149907e-05</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>2.074195e-06</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>313204866</td>\n",
       "      <td>afa2cb1ec5c2dcdbb04a882dba782fd5.jpg</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.082693</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.797344e-06</td>\n",
       "      <td>8.341804e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.100346e-05</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>338683900</td>\n",
       "      <td>ba8360f9a8ab43104543dfe7e95f7127.jpg</td>\n",
       "      <td>0.068541</td>\n",
       "      <td>0.336474</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>0.070102</td>\n",
       "      <td>0.153625</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.015174</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.249834e-03</td>\n",
       "      <td>1.126373e-03</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>4.924853e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>341051995</td>\n",
       "      <td>199de1d6816ef883542d5e5d3e60dd14.jpg</td>\n",
       "      <td>0.072777</td>\n",
       "      <td>0.494129</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.103254</td>\n",
       "      <td>0.181899</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>...</td>\n",
       "      <td>5.083560e-04</td>\n",
       "      <td>1.562075e-03</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.061935e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>418148173</td>\n",
       "      <td>28c722eef3446f0eb0467f307eb2c0c6.jpg</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.872326</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.065166</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.767056e-06</td>\n",
       "      <td>2.716022e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.509388e-06</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>422206226</td>\n",
       "      <td>94db0ae1705e817615495b76ba729956.jpg</td>\n",
       "      <td>0.103729</td>\n",
       "      <td>0.105288</td>\n",
       "      <td>0.087196</td>\n",
       "      <td>0.072994</td>\n",
       "      <td>0.250969</td>\n",
       "      <td>0.008650</td>\n",
       "      <td>0.032923</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>...</td>\n",
       "      <td>2.186876e-03</td>\n",
       "      <td>1.699440e-03</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>2.005548e-03</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>446486078</td>\n",
       "      <td>13d54011ec5f885e4e3c8a50160c84f2.jpg</td>\n",
       "      <td>0.041743</td>\n",
       "      <td>0.016660</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.029328</td>\n",
       "      <td>0.083659</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.718465</td>\n",
       "      <td>...</td>\n",
       "      <td>3.668662e-03</td>\n",
       "      <td>4.347140e-04</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>3.497707e-04</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>449405711</td>\n",
       "      <td>05e5bbd6873a335504a64e347befe327.jpg</td>\n",
       "      <td>0.226316</td>\n",
       "      <td>0.061332</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>0.295321</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.140598</td>\n",
       "      <td>...</td>\n",
       "      <td>3.631575e-03</td>\n",
       "      <td>2.312359e-04</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>3.980284e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>470919626</td>\n",
       "      <td>f6f54a7a0ff84157bd957d7badd911ff.jpg</td>\n",
       "      <td>0.173879</td>\n",
       "      <td>0.330026</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>0.034426</td>\n",
       "      <td>0.149228</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120359e-03</td>\n",
       "      <td>7.499963e-04</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>6.472109e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>491758404</td>\n",
       "      <td>194a7bfe023c6c646dea3e1c0a7d0612.jpg</td>\n",
       "      <td>0.217989</td>\n",
       "      <td>0.082206</td>\n",
       "      <td>0.034651</td>\n",
       "      <td>0.051538</td>\n",
       "      <td>0.076644</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>...</td>\n",
       "      <td>9.038874e-05</td>\n",
       "      <td>1.485349e-04</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>5.949422e-05</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>504090525</td>\n",
       "      <td>d4db02d0a928b6403b38b07b718584f0.jpg</td>\n",
       "      <td>0.670800</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.088545</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>...</td>\n",
       "      <td>3.379253e-04</td>\n",
       "      <td>1.004234e-03</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>1.554478e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>524948814</td>\n",
       "      <td>1a67c4ff1ff0b8a78f3a79126bbd8a10.jpg</td>\n",
       "      <td>0.234005</td>\n",
       "      <td>0.385632</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.234935</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>...</td>\n",
       "      <td>8.168832e-05</td>\n",
       "      <td>1.817997e-04</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>7.001213e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32035</th>\n",
       "      <td>1273543823</td>\n",
       "      <td>78877a914a37217aca997b0c57563fa5.jpg</td>\n",
       "      <td>0.858376</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.089492</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724834e-04</td>\n",
       "      <td>7.527986e-05</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>4.581277e-05</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32036</th>\n",
       "      <td>1275604000</td>\n",
       "      <td>02c1934a2b36c398d1652ac185301acc.jpg</td>\n",
       "      <td>0.169298</td>\n",
       "      <td>0.193885</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.107193</td>\n",
       "      <td>0.377438</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>...</td>\n",
       "      <td>4.593781e-04</td>\n",
       "      <td>1.676142e-04</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>2.267876e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32037</th>\n",
       "      <td>1281724516</td>\n",
       "      <td>1a3673c285674ed940fda7a429051d06.jpg</td>\n",
       "      <td>0.113229</td>\n",
       "      <td>0.101441</td>\n",
       "      <td>0.077595</td>\n",
       "      <td>0.162764</td>\n",
       "      <td>0.272014</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>0.034354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746326e-04</td>\n",
       "      <td>2.509702e-04</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>3.775508e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32038</th>\n",
       "      <td>1291196376</td>\n",
       "      <td>ad60b6b7de827a4d433e3bbece6827a7.jpg</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.709991</td>\n",
       "      <td>0.073504</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>...</td>\n",
       "      <td>2.722226e-05</td>\n",
       "      <td>1.988675e-04</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.802536e-05</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32039</th>\n",
       "      <td>1297407159</td>\n",
       "      <td>13069bb536b4a4fea4ce5ace014728f2.jpg</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.456217</td>\n",
       "      <td>0.035602</td>\n",
       "      <td>0.046086</td>\n",
       "      <td>0.177250</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.008988</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>...</td>\n",
       "      <td>2.960577e-04</td>\n",
       "      <td>5.670877e-04</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>3.059054e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32040</th>\n",
       "      <td>1304431457</td>\n",
       "      <td>21b9fcc5745c0d834cdec002f97c7755.jpg</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.089817</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.340560</td>\n",
       "      <td>0.282016</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>...</td>\n",
       "      <td>3.454767e-05</td>\n",
       "      <td>1.325822e-03</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>1.038396e-04</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32041</th>\n",
       "      <td>1310711505</td>\n",
       "      <td>eb9ea2dbf986c7d5e7fbf295ab65f164.jpg</td>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.030495</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.320716</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.030842</td>\n",
       "      <td>0.035472</td>\n",
       "      <td>...</td>\n",
       "      <td>4.996546e-04</td>\n",
       "      <td>1.173804e-03</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>1.666871e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32042</th>\n",
       "      <td>1311114273</td>\n",
       "      <td>1d1ba5d0f6c689faf092d4fc9d6763fd.jpg</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.227768</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>...</td>\n",
       "      <td>2.410936e-06</td>\n",
       "      <td>5.910965e-03</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3.947609e-05</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32043</th>\n",
       "      <td>1336439069</td>\n",
       "      <td>c8c00e2a18a47f874b8bbb0d9ae14355.jpg</td>\n",
       "      <td>0.104844</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.113538</td>\n",
       "      <td>0.125997</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>...</td>\n",
       "      <td>6.288440e-05</td>\n",
       "      <td>9.611899e-04</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1.361495e-05</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32044</th>\n",
       "      <td>1340543586</td>\n",
       "      <td>bde707c542c852dda9776df777cbbebb.jpg</td>\n",
       "      <td>0.226745</td>\n",
       "      <td>0.057893</td>\n",
       "      <td>0.026298</td>\n",
       "      <td>0.287147</td>\n",
       "      <td>0.263958</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432075e-03</td>\n",
       "      <td>1.046802e-04</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>2.418939e-04</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32045</th>\n",
       "      <td>1374114943</td>\n",
       "      <td>7541990a97d94a0339a4731ca826cec3.jpg</td>\n",
       "      <td>0.196185</td>\n",
       "      <td>0.210260</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.110472</td>\n",
       "      <td>0.242835</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.012287</td>\n",
       "      <td>...</td>\n",
       "      <td>3.793353e-04</td>\n",
       "      <td>4.118443e-04</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>3.037785e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32046</th>\n",
       "      <td>1374385065</td>\n",
       "      <td>b557d580dbb3ae548e0836ea64dc32e7.jpg</td>\n",
       "      <td>0.072183</td>\n",
       "      <td>0.309030</td>\n",
       "      <td>0.024388</td>\n",
       "      <td>0.082702</td>\n",
       "      <td>0.247227</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>...</td>\n",
       "      <td>1.802246e-03</td>\n",
       "      <td>1.893525e-03</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>7.176239e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32047</th>\n",
       "      <td>1385467058</td>\n",
       "      <td>e42b9df4299e0b94982eee6cd5a063a6.jpg</td>\n",
       "      <td>0.116741</td>\n",
       "      <td>0.161830</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.245767</td>\n",
       "      <td>0.386838</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695780e-04</td>\n",
       "      <td>3.679159e-04</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>2.751683e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32048</th>\n",
       "      <td>1388694391</td>\n",
       "      <td>e8247eebb1793ec7da5eaaa9433c477d.jpg</td>\n",
       "      <td>0.030086</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.751809</td>\n",
       "      <td>0.158392</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>3.824890e-06</td>\n",
       "      <td>4.296168e-06</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.293131e-05</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32049</th>\n",
       "      <td>1388952914</td>\n",
       "      <td>b05afa01cc1b38c0d0844aab657ea6d7.jpg</td>\n",
       "      <td>0.345131</td>\n",
       "      <td>0.042746</td>\n",
       "      <td>0.037050</td>\n",
       "      <td>0.145907</td>\n",
       "      <td>0.192386</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>...</td>\n",
       "      <td>6.445705e-05</td>\n",
       "      <td>2.325469e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>1.107568e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32050</th>\n",
       "      <td>1390309490</td>\n",
       "      <td>f5fea450902ae4ce2afc9017775f7a4a.jpg</td>\n",
       "      <td>0.060489</td>\n",
       "      <td>0.060434</td>\n",
       "      <td>0.020205</td>\n",
       "      <td>0.159372</td>\n",
       "      <td>0.204580</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>...</td>\n",
       "      <td>3.836293e-03</td>\n",
       "      <td>2.212004e-03</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>1.755475e-03</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32051</th>\n",
       "      <td>1392099029</td>\n",
       "      <td>ac9c019456d8a6c6be52745a717fabb9.jpg</td>\n",
       "      <td>0.046375</td>\n",
       "      <td>0.044313</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.009707</td>\n",
       "      <td>0.196540</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>...</td>\n",
       "      <td>8.283770e-05</td>\n",
       "      <td>3.601380e-03</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>4.177136e-04</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32052</th>\n",
       "      <td>1393477320</td>\n",
       "      <td>a0da70246d32af0252656a339bf7c560.jpg</td>\n",
       "      <td>0.097102</td>\n",
       "      <td>0.078003</td>\n",
       "      <td>0.031133</td>\n",
       "      <td>0.104181</td>\n",
       "      <td>0.171443</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.018838</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537792e-03</td>\n",
       "      <td>8.506162e-04</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>5.950645e-04</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32053</th>\n",
       "      <td>1396422677</td>\n",
       "      <td>e98fcc3620be1e384653a3c7fee67f04.jpg</td>\n",
       "      <td>0.230682</td>\n",
       "      <td>0.182826</td>\n",
       "      <td>0.031147</td>\n",
       "      <td>0.214570</td>\n",
       "      <td>0.208350</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>...</td>\n",
       "      <td>2.127999e-04</td>\n",
       "      <td>1.050568e-03</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>4.039879e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32054</th>\n",
       "      <td>1396978416</td>\n",
       "      <td>634c1abe3e4c1b91fb57708a8e43ae31.jpg</td>\n",
       "      <td>0.047506</td>\n",
       "      <td>0.084842</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.066806</td>\n",
       "      <td>0.148620</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>...</td>\n",
       "      <td>9.131782e-05</td>\n",
       "      <td>1.196918e-03</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>7.705132e-05</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32055</th>\n",
       "      <td>1397399499</td>\n",
       "      <td>bc95ee3f5d7336a9a974f76792a5d05c.jpg</td>\n",
       "      <td>0.128770</td>\n",
       "      <td>0.275420</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.061891</td>\n",
       "      <td>0.157637</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.053643</td>\n",
       "      <td>...</td>\n",
       "      <td>5.702250e-03</td>\n",
       "      <td>9.517859e-04</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.009685</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.076035</td>\n",
       "      <td>6.083354e-03</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32056</th>\n",
       "      <td>1412221811</td>\n",
       "      <td>eef28f5857b5a480e3c3c9b352d167a6.jpg</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>3.242152e-07</td>\n",
       "      <td>3.454421e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>3.665442e-06</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32057</th>\n",
       "      <td>1434199792</td>\n",
       "      <td>6f4d475c14adf8374535ba40979e3832.jpg</td>\n",
       "      <td>0.087468</td>\n",
       "      <td>0.232359</td>\n",
       "      <td>0.147299</td>\n",
       "      <td>0.107629</td>\n",
       "      <td>0.162355</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.031786</td>\n",
       "      <td>...</td>\n",
       "      <td>3.377912e-04</td>\n",
       "      <td>6.110207e-05</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>2.326245e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32058</th>\n",
       "      <td>1437784757</td>\n",
       "      <td>90237d99da82bea3d62a25717d6b37ef.jpg</td>\n",
       "      <td>0.020743</td>\n",
       "      <td>0.136117</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>0.141298</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174783e-04</td>\n",
       "      <td>4.914620e-03</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>9.568218e-05</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32059</th>\n",
       "      <td>1449968955</td>\n",
       "      <td>f25ff94a4ff170f2cf42ccba707130a6.jpg</td>\n",
       "      <td>0.096119</td>\n",
       "      <td>0.034784</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.188180</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.883971e-04</td>\n",
       "      <td>2.036270e-03</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.031179</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>1.738270e-03</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060</th>\n",
       "      <td>1462488173</td>\n",
       "      <td>d85074b8201b3a04cf3dcce79675eefb.jpg</td>\n",
       "      <td>0.037835</td>\n",
       "      <td>0.113908</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.030171</td>\n",
       "      <td>0.210019</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>...</td>\n",
       "      <td>9.494813e-04</td>\n",
       "      <td>2.150581e-03</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>1.018450e-03</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32061</th>\n",
       "      <td>1468185595</td>\n",
       "      <td>f6292d6b47aa07b85834208f3e24253e.jpg</td>\n",
       "      <td>0.843320</td>\n",
       "      <td>0.014704</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>0.087250</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>...</td>\n",
       "      <td>2.085352e-04</td>\n",
       "      <td>8.718170e-05</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5.085918e-05</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32062</th>\n",
       "      <td>1475407681</td>\n",
       "      <td>a4100cd068e859ce6b7e8b956cc5bd5e.jpg</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>3.815128e-07</td>\n",
       "      <td>1.853525e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6.897422e-07</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32063</th>\n",
       "      <td>1507136447</td>\n",
       "      <td>4f07fd3529a5b44e95a3646291fa00f7.jpg</td>\n",
       "      <td>0.655870</td>\n",
       "      <td>0.063511</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.044143</td>\n",
       "      <td>0.137766</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>...</td>\n",
       "      <td>8.344228e-04</td>\n",
       "      <td>5.305725e-04</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>1.335893e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32064</th>\n",
       "      <td>1510470376</td>\n",
       "      <td>2bbbf3ed6fcfa0480278ea1b50557ac4.jpg</td>\n",
       "      <td>0.041456</td>\n",
       "      <td>0.217191</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.025290</td>\n",
       "      <td>0.256715</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>...</td>\n",
       "      <td>2.218864e-05</td>\n",
       "      <td>2.638769e-03</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>2.455859e-04</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32065 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           itemid                                 index        31        32  \\\n",
       "0         2816338  3b9a11608551b11b9330268e0d055e01.jpg  0.883424  0.012605   \n",
       "1         9503620  a23f0381039e5595559be27db3271d2f.jpg  0.278721  0.177533   \n",
       "2        26702291  2c0ea46a95837e5171bd43512e82b1ce.jpg  0.001377  0.978527   \n",
       "3        74050515  9a28a64c29e97e52c71ed45b029281ec.jpg  0.601693  0.033724   \n",
       "4       122874123  3cfd98eb1f103623e12b8f081d702a66.jpg  0.048917  0.014367   \n",
       "5       148667803  083faffd864dd1e6aff8cbc892ac15d7.jpg  0.623251  0.154122   \n",
       "6       193655696  c1b8da227c7d1d4a4edd84496e914771.jpg  0.030702  0.029294   \n",
       "7       210801578  f14091a8b8a09cd6b5e64b6ae2b45185.jpg  0.277034  0.214561   \n",
       "8       212660404  39ed4573ea35e9b4e4619f37734c512a.jpg  0.014043  0.899937   \n",
       "9       213418407  d961511fb22ca5eec825219035c0e1d4.jpg  0.005258  0.458902   \n",
       "10      224567557  b1578dd4fea374e77138f9a933b8d73c.jpg  0.067444  0.332045   \n",
       "11      257562289  b557939f68ad26ddde7012a5fd854560.jpg  0.811060  0.035738   \n",
       "12      269996732  d67af08316609b9b66e63da4e4c26034.jpg  0.077402  0.058425   \n",
       "13      270365319  b0bdaf97069f7b09c2332d0fb0de56e9.jpg  0.223796  0.204085   \n",
       "14      279946181  4540b00617a6a9f484e8c9141ff2333a.jpg  0.564261  0.062500   \n",
       "15      283137033  27a70936648c2ec958cbf7bf96e650c8.jpg  0.018005  0.010208   \n",
       "16      287953674  7436a65bb4ebfca250eee6bdbc0d8094.jpg  0.003019  0.009024   \n",
       "17      290669247  21f4a6682d77fa308b453ce8b71175d8.jpg  0.137716  0.510536   \n",
       "18      301704723  932d462d21c2f5afdcc98219c8a09cb7.jpg  0.836098  0.014227   \n",
       "19      313204866  afa2cb1ec5c2dcdbb04a882dba782fd5.jpg  0.003844  0.002155   \n",
       "20      338683900  ba8360f9a8ab43104543dfe7e95f7127.jpg  0.068541  0.336474   \n",
       "21      341051995  199de1d6816ef883542d5e5d3e60dd14.jpg  0.072777  0.494129   \n",
       "22      418148173  28c722eef3446f0eb0467f307eb2c0c6.jpg  0.002232  0.872326   \n",
       "23      422206226  94db0ae1705e817615495b76ba729956.jpg  0.103729  0.105288   \n",
       "24      446486078  13d54011ec5f885e4e3c8a50160c84f2.jpg  0.041743  0.016660   \n",
       "25      449405711  05e5bbd6873a335504a64e347befe327.jpg  0.226316  0.061332   \n",
       "26      470919626  f6f54a7a0ff84157bd957d7badd911ff.jpg  0.173879  0.330026   \n",
       "27      491758404  194a7bfe023c6c646dea3e1c0a7d0612.jpg  0.217989  0.082206   \n",
       "28      504090525  d4db02d0a928b6403b38b07b718584f0.jpg  0.670800  0.032671   \n",
       "29      524948814  1a67c4ff1ff0b8a78f3a79126bbd8a10.jpg  0.234005  0.385632   \n",
       "...           ...                                   ...       ...       ...   \n",
       "32035  1273543823  78877a914a37217aca997b0c57563fa5.jpg  0.858376  0.012433   \n",
       "32036  1275604000  02c1934a2b36c398d1652ac185301acc.jpg  0.169298  0.193885   \n",
       "32037  1281724516  1a3673c285674ed940fda7a429051d06.jpg  0.113229  0.101441   \n",
       "32038  1291196376  ad60b6b7de827a4d433e3bbece6827a7.jpg  0.035553  0.005982   \n",
       "32039  1297407159  13069bb536b4a4fea4ce5ace014728f2.jpg  0.059621  0.456217   \n",
       "32040  1304431457  21b9fcc5745c0d834cdec002f97c7755.jpg  0.019465  0.089817   \n",
       "32041  1310711505  eb9ea2dbf986c7d5e7fbf295ab65f164.jpg  0.020445  0.030495   \n",
       "32042  1311114273  1d1ba5d0f6c689faf092d4fc9d6763fd.jpg  0.014526  0.031331   \n",
       "32043  1336439069  c8c00e2a18a47f874b8bbb0d9ae14355.jpg  0.104844  0.020335   \n",
       "32044  1340543586  bde707c542c852dda9776df777cbbebb.jpg  0.226745  0.057893   \n",
       "32045  1374114943  7541990a97d94a0339a4731ca826cec3.jpg  0.196185  0.210260   \n",
       "32046  1374385065  b557d580dbb3ae548e0836ea64dc32e7.jpg  0.072183  0.309030   \n",
       "32047  1385467058  e42b9df4299e0b94982eee6cd5a063a6.jpg  0.116741  0.161830   \n",
       "32048  1388694391  e8247eebb1793ec7da5eaaa9433c477d.jpg  0.030086  0.010893   \n",
       "32049  1388952914  b05afa01cc1b38c0d0844aab657ea6d7.jpg  0.345131  0.042746   \n",
       "32050  1390309490  f5fea450902ae4ce2afc9017775f7a4a.jpg  0.060489  0.060434   \n",
       "32051  1392099029  ac9c019456d8a6c6be52745a717fabb9.jpg  0.046375  0.044313   \n",
       "32052  1393477320  a0da70246d32af0252656a339bf7c560.jpg  0.097102  0.078003   \n",
       "32053  1396422677  e98fcc3620be1e384653a3c7fee67f04.jpg  0.230682  0.182826   \n",
       "32054  1396978416  634c1abe3e4c1b91fb57708a8e43ae31.jpg  0.047506  0.084842   \n",
       "32055  1397399499  bc95ee3f5d7336a9a974f76792a5d05c.jpg  0.128770  0.275420   \n",
       "32056  1412221811  eef28f5857b5a480e3c3c9b352d167a6.jpg  0.000349  0.001648   \n",
       "32057  1434199792  6f4d475c14adf8374535ba40979e3832.jpg  0.087468  0.232359   \n",
       "32058  1437784757  90237d99da82bea3d62a25717d6b37ef.jpg  0.020743  0.136117   \n",
       "32059  1449968955  f25ff94a4ff170f2cf42ccba707130a6.jpg  0.096119  0.034784   \n",
       "32060  1462488173  d85074b8201b3a04cf3dcce79675eefb.jpg  0.037835  0.113908   \n",
       "32061  1468185595  f6292d6b47aa07b85834208f3e24253e.jpg  0.843320  0.014704   \n",
       "32062  1475407681  a4100cd068e859ce6b7e8b956cc5bd5e.jpg  0.000904  0.000258   \n",
       "32063  1507136447  4f07fd3529a5b44e95a3646291fa00f7.jpg  0.655870  0.063511   \n",
       "32064  1510470376  2bbbf3ed6fcfa0480278ea1b50557ac4.jpg  0.041456  0.217191   \n",
       "\n",
       "             33        34        35        36        37        38    ...     \\\n",
       "0      0.000212  0.016350  0.073758  0.000144  0.000176  0.000084    ...      \n",
       "1      0.003252  0.070696  0.063292  0.001435  0.000578  0.001302    ...      \n",
       "2      0.000005  0.003402  0.013050  0.000007  0.000013  0.000019    ...      \n",
       "3      0.028193  0.028183  0.180513  0.002939  0.007077  0.011178    ...      \n",
       "4      0.001691  0.500844  0.248733  0.000180  0.003880  0.000100    ...      \n",
       "5      0.004254  0.039050  0.051524  0.000153  0.003944  0.000892    ...      \n",
       "6      0.002633  0.014957  0.078660  0.802044  0.003124  0.009234    ...      \n",
       "7      0.084110  0.074292  0.241911  0.001167  0.019214  0.004437    ...      \n",
       "8      0.000496  0.012193  0.026526  0.000140  0.000853  0.005278    ...      \n",
       "9      0.001525  0.233880  0.271702  0.000182  0.001247  0.002195    ...      \n",
       "10     0.002005  0.017474  0.295736  0.021220  0.079622  0.021355    ...      \n",
       "11     0.004086  0.024902  0.072940  0.000004  0.000100  0.000437    ...      \n",
       "12     0.483558  0.063054  0.129270  0.000188  0.009440  0.001860    ...      \n",
       "13     0.015895  0.079600  0.116897  0.000426  0.014926  0.007848    ...      \n",
       "14     0.007461  0.036000  0.028366  0.000168  0.002070  0.000089    ...      \n",
       "15     0.000484  0.045256  0.072630  0.000216  0.002624  0.003049    ...      \n",
       "16     0.000072  0.010293  0.021487  0.000006  0.000105  0.000005    ...      \n",
       "17     0.003766  0.064764  0.120508  0.001294  0.003368  0.002923    ...      \n",
       "18     0.000195  0.008020  0.027920  0.000005  0.000031  0.000077    ...      \n",
       "19     0.000282  0.010111  0.082693  0.000003  0.002545  0.000003    ...      \n",
       "20     0.022920  0.070102  0.153625  0.001954  0.015174  0.028000    ...      \n",
       "21     0.004260  0.103254  0.181899  0.000724  0.008714  0.004992    ...      \n",
       "22     0.000013  0.000949  0.065166  0.000103  0.000574  0.005087    ...      \n",
       "23     0.087196  0.072994  0.250969  0.008650  0.032923  0.004555    ...      \n",
       "24     0.002434  0.029328  0.083659  0.003148  0.006252  0.718465    ...      \n",
       "25     0.019177  0.040398  0.295321  0.004277  0.013225  0.140598    ...      \n",
       "26     0.008267  0.034426  0.149228  0.008968  0.004724  0.031349    ...      \n",
       "27     0.034651  0.051538  0.076644  0.000079  0.003202  0.000936    ...      \n",
       "28     0.001365  0.032333  0.088545  0.002556  0.003781  0.003120    ...      \n",
       "29     0.003752  0.009471  0.234935  0.000911  0.004638  0.008220    ...      \n",
       "...         ...       ...       ...       ...       ...       ...    ...      \n",
       "32035  0.005625  0.014682  0.089492  0.000042  0.000729  0.000534    ...      \n",
       "32036  0.007945  0.107193  0.377438  0.000167  0.004299  0.000903    ...      \n",
       "32037  0.077595  0.162764  0.272014  0.012044  0.036603  0.034354    ...      \n",
       "32038  0.003910  0.709991  0.073504  0.000007  0.000462  0.000063    ...      \n",
       "32039  0.035602  0.046086  0.177250  0.003518  0.008988  0.006885    ...      \n",
       "32040  0.003991  0.340560  0.282016  0.000036  0.003662  0.005684    ...      \n",
       "32041  0.002704  0.035525  0.320716  0.000430  0.030842  0.035472    ...      \n",
       "32042  0.000383  0.017047  0.227768  0.000012  0.003904  0.000469    ...      \n",
       "32043  0.000682  0.113538  0.125997  0.000013  0.007686  0.000614    ...      \n",
       "32044  0.026298  0.287147  0.263958  0.004200  0.025192  0.008761    ...      \n",
       "32045  0.061353  0.110472  0.242835  0.001620  0.011787  0.012287    ...      \n",
       "32046  0.024388  0.082702  0.247227  0.005284  0.008631  0.012620    ...      \n",
       "32047  0.007661  0.245767  0.386838  0.001474  0.006275  0.004689    ...      \n",
       "32048  0.001942  0.751809  0.158392  0.000003  0.000226  0.000023    ...      \n",
       "32049  0.037050  0.145907  0.192386  0.000305  0.018055  0.001137    ...      \n",
       "32050  0.020205  0.159372  0.204580  0.001149  0.012304  0.010736    ...      \n",
       "32051  0.000482  0.009707  0.196540  0.000092  0.012566  0.003916    ...      \n",
       "32052  0.031133  0.104181  0.171443  0.003097  0.018838  0.010893    ...      \n",
       "32053  0.031147  0.214570  0.208350  0.000908  0.010656  0.003372    ...      \n",
       "32054  0.001713  0.066806  0.148620  0.000685  0.003521  0.004825    ...      \n",
       "32055  0.001656  0.061891  0.157637  0.017484  0.013829  0.053643    ...      \n",
       "32056  0.000057  0.001124  0.007383  0.000001  0.000067  0.000064    ...      \n",
       "32057  0.147299  0.107629  0.162355  0.027453  0.007591  0.031786    ...      \n",
       "32058  0.001603  0.014609  0.141298  0.000051  0.000714  0.001182    ...      \n",
       "32059  0.000005  0.010585  0.188180  0.000007  0.000609  0.000036    ...      \n",
       "32060  0.002937  0.030171  0.210019  0.000494  0.001895  0.002580    ...      \n",
       "32061  0.001987  0.016289  0.087250  0.000075  0.001622  0.000245    ...      \n",
       "32062  0.000011  0.006059  0.033938  0.000003  0.000016  0.000010    ...      \n",
       "32063  0.006633  0.044143  0.137766  0.008113  0.003756  0.009870    ...      \n",
       "32064  0.001089  0.025290  0.256715  0.000098  0.000496  0.000303    ...      \n",
       "\n",
       "                 50            51        52        53        54        55  \\\n",
       "0      2.546633e-05  1.471064e-05  0.000021  0.000019  0.000057  0.000040   \n",
       "1      3.675401e-04  1.966892e-04  0.000595  0.000358  0.000317  0.000214   \n",
       "2      2.433453e-07  1.700982e-06  0.000048  0.000004  0.000006  0.000010   \n",
       "3      2.531332e-03  1.450678e-04  0.000201  0.000203  0.000186  0.000221   \n",
       "4      7.084288e-05  2.756204e-05  0.000732  0.000258  0.000125  0.000090   \n",
       "5      1.371836e-05  4.439028e-04  0.000025  0.000118  0.000064  0.000020   \n",
       "6      7.922183e-04  1.047876e-04  0.000475  0.002041  0.000055  0.000551   \n",
       "7      8.234581e-05  8.576331e-05  0.000280  0.003183  0.000413  0.000417   \n",
       "8      2.121018e-05  4.890963e-04  0.000072  0.000279  0.000517  0.000105   \n",
       "9      3.200407e-05  4.720400e-04  0.000090  0.002059  0.000435  0.000022   \n",
       "10     1.802436e-03  3.505952e-04  0.001632  0.000634  0.000896  0.001176   \n",
       "11     5.979235e-06  1.858851e-04  0.000060  0.000062  0.000027  0.000011   \n",
       "12     1.249744e-04  4.856712e-05  0.000558  0.000253  0.000042  0.000226   \n",
       "13     2.191225e-04  4.023139e-04  0.000335  0.001278  0.002395  0.000421   \n",
       "14     1.093048e-04  3.789398e-05  0.000204  0.000414  0.000600  0.000058   \n",
       "15     1.990368e-03  1.785333e-04  0.003514  0.016177  0.000067  0.000351   \n",
       "16     3.638710e-05  8.756408e-05  0.000118  0.000106  0.000177  0.000241   \n",
       "17     3.095026e-05  9.943701e-05  0.000052  0.000038  0.000100  0.000068   \n",
       "18     3.369434e-07  1.149907e-05  0.000011  0.000004  0.000004  0.000004   \n",
       "19     1.797344e-06  8.341804e-06  0.000006  0.000012  0.000163  0.000014   \n",
       "20     1.249834e-03  1.126373e-03  0.001273  0.012071  0.000299  0.001282   \n",
       "21     5.083560e-04  1.562075e-03  0.000238  0.000458  0.000635  0.000374   \n",
       "22     1.767056e-06  2.716022e-06  0.000009  0.000014  0.000010  0.000035   \n",
       "23     2.186876e-03  1.699440e-03  0.001640  0.009082  0.004909  0.002054   \n",
       "24     3.668662e-03  4.347140e-04  0.001839  0.004523  0.000298  0.003170   \n",
       "25     3.631575e-03  2.312359e-04  0.000562  0.001927  0.000071  0.000172   \n",
       "26     1.120359e-03  7.499963e-04  0.002817  0.006259  0.000178  0.000806   \n",
       "27     9.038874e-05  1.485349e-04  0.000119  0.000158  0.000050  0.000062   \n",
       "28     3.379253e-04  1.004234e-03  0.000212  0.002205  0.000143  0.000174   \n",
       "29     8.168832e-05  1.817997e-04  0.000138  0.001061  0.000054  0.000130   \n",
       "...             ...           ...       ...       ...       ...       ...   \n",
       "32035  1.724834e-04  7.527986e-05  0.000091  0.000039  0.000169  0.000133   \n",
       "32036  4.593781e-04  1.676142e-04  0.000558  0.031558  0.000633  0.000105   \n",
       "32037  1.746326e-04  2.509702e-04  0.000466  0.000912  0.000980  0.000632   \n",
       "32038  2.722226e-05  1.988675e-04  0.000030  0.000017  0.000040  0.000036   \n",
       "32039  2.960577e-04  5.670877e-04  0.000889  0.000428  0.000363  0.000412   \n",
       "32040  3.454767e-05  1.325822e-03  0.000420  0.000129  0.000421  0.000210   \n",
       "32041  4.996546e-04  1.173804e-03  0.000144  0.000300  0.000077  0.000926   \n",
       "32042  2.410936e-06  5.910965e-03  0.000383  0.000028  0.000076  0.000326   \n",
       "32043  6.288440e-05  9.611899e-04  0.000098  0.000453  0.000065  0.000048   \n",
       "32044  1.432075e-03  1.046802e-04  0.000328  0.001777  0.000146  0.000677   \n",
       "32045  3.793353e-04  4.118443e-04  0.000733  0.000389  0.001841  0.000603   \n",
       "32046  1.802246e-03  1.893525e-03  0.000957  0.000916  0.006873  0.000945   \n",
       "32047  2.695780e-04  3.679159e-04  0.000289  0.008831  0.000337  0.000084   \n",
       "32048  3.824890e-06  4.296168e-06  0.000119  0.000084  0.000005  0.000012   \n",
       "32049  6.445705e-05  2.325469e-04  0.000071  0.001406  0.000674  0.000225   \n",
       "32050  3.836293e-03  2.212004e-03  0.002660  0.001575  0.001155  0.002837   \n",
       "32051  8.283770e-05  3.601380e-03  0.000558  0.013633  0.001298  0.003858   \n",
       "32052  1.537792e-03  8.506162e-04  0.001029  0.002757  0.000762  0.000954   \n",
       "32053  2.127999e-04  1.050568e-03  0.000888  0.002797  0.001380  0.000272   \n",
       "32054  9.131782e-05  1.196918e-03  0.000096  0.000133  0.000109  0.000192   \n",
       "32055  5.702250e-03  9.517859e-04  0.008892  0.009685  0.005302  0.003181   \n",
       "32056  3.242152e-07  3.454421e-07  0.000005  0.000038  0.000071  0.000015   \n",
       "32057  3.377912e-04  6.110207e-05  0.000404  0.001946  0.000119  0.000355   \n",
       "32058  1.174783e-04  4.914620e-03  0.000029  0.000151  0.000842  0.000092   \n",
       "32059  1.883971e-04  2.036270e-03  0.002710  0.000093  0.031179  0.000151   \n",
       "32060  9.494813e-04  2.150581e-03  0.003053  0.002906  0.002119  0.000762   \n",
       "32061  2.085352e-04  8.718170e-05  0.000153  0.000174  0.000021  0.000093   \n",
       "32062  3.815128e-07  1.853525e-06  0.000006  0.000009  0.000008  0.000004   \n",
       "32063  8.344228e-04  5.305725e-04  0.000498  0.003958  0.000360  0.000203   \n",
       "32064  2.218864e-05  2.638769e-03  0.000510  0.000027  0.009357  0.000440   \n",
       "\n",
       "             56            57  final_pred  Category  \n",
       "0      0.000084  1.323019e-05          31        31  \n",
       "1      0.001195  1.328025e-04          41        31  \n",
       "2      0.000034  1.335207e-06          32        32  \n",
       "3      0.000318  3.438597e-04          31        31  \n",
       "4      0.000650  1.623501e-04          34        34  \n",
       "5      0.000081  3.032195e-05          31        31  \n",
       "6      0.000276  1.658877e-04          36        36  \n",
       "7      0.000455  1.556106e-04          31        32  \n",
       "8      0.000717  5.743321e-05          32        32  \n",
       "9      0.000331  8.762698e-05          32        32  \n",
       "10     0.000773  6.480849e-04          32        35  \n",
       "11     0.000138  1.615911e-05          31        31  \n",
       "12     0.000588  1.212007e-04          33        31  \n",
       "13     0.000371  3.163820e-04          31        31  \n",
       "14     0.000089  5.387356e-05          31        31  \n",
       "15     0.000864  1.444049e-03          44        44  \n",
       "16     0.000097  1.077856e-04          42        42  \n",
       "17     0.000138  5.831746e-05          32        32  \n",
       "18     0.000058  2.074195e-06          31        31  \n",
       "19     0.000023  1.100346e-05          41        41  \n",
       "20     0.000513  4.924853e-04          32        32  \n",
       "21     0.000521  1.061935e-04          32        32  \n",
       "22     0.000047  2.509388e-06          32        32  \n",
       "23     0.000614  2.005548e-03          35        33  \n",
       "24     0.000375  3.497707e-04          38        38  \n",
       "25     0.000376  3.980284e-04          35        38  \n",
       "26     0.001235  6.472109e-04          32        32  \n",
       "27     0.000214  5.949422e-05          41        31  \n",
       "28     0.001476  1.554478e-04          31        31  \n",
       "29     0.000424  7.001213e-05          32        32  \n",
       "...         ...           ...         ...       ...  \n",
       "32035  0.000092  4.581277e-05          31        31  \n",
       "32036  0.002812  2.267876e-04          35        42  \n",
       "32037  0.000292  3.775508e-04          35        32  \n",
       "32038  0.000144  1.802536e-05          34        35  \n",
       "32039  0.000782  3.059054e-04          32        35  \n",
       "32040  0.000427  1.038396e-04          34        35  \n",
       "32041  0.000141  1.666871e-04          35        35  \n",
       "32042  0.000042  3.947609e-05          43        35  \n",
       "32043  0.000049  1.361495e-05          41        42  \n",
       "32044  0.001929  2.418939e-04          34        31  \n",
       "32045  0.000952  3.037785e-04          35        32  \n",
       "32046  0.001334  7.176239e-04          32        32  \n",
       "32047  0.000836  2.751683e-04          35        34  \n",
       "32048  0.000027  1.293131e-05          34        35  \n",
       "32049  0.000127  1.107568e-04          31        37  \n",
       "32050  0.002724  1.755475e-03          35        38  \n",
       "32051  0.001845  4.177136e-04          42        45  \n",
       "32052  0.000677  5.950645e-04          41        41  \n",
       "32053  0.000584  4.039879e-04          31        35  \n",
       "32054  0.000310  7.705132e-05          41        41  \n",
       "32055  0.076035  6.083354e-03          32        56  \n",
       "32056  0.000081  3.665442e-06          41        41  \n",
       "32057  0.000437  2.326245e-04          32        48  \n",
       "32058  0.000475  9.568218e-05          41        35  \n",
       "32059  0.003617  1.738270e-03          42        42  \n",
       "32060  0.000456  1.018450e-03          42        42  \n",
       "32061  0.000179  5.085918e-05          31        31  \n",
       "32062  0.000009  6.897422e-07          41        41  \n",
       "32063  0.000132  1.335893e-04          31        35  \n",
       "32064  0.001035  2.455859e-04          42        32  \n",
       "\n",
       "[32065 rows x 31 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(df_im['mobile_'][0],on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    df=pd.DataFrame(predictions_proba[groups[i]])\n",
    "    df.columns=classes[groups[i]]\n",
    "    df['pred']=df.idxmax(axis=1)\n",
    "    df['itemid']=df_test[df_test.Group==groups[i]].itemid.values\n",
    "    df.to_csv(groups[i]+'_test_proba_nlp_all_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pipe.predict(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70672370657017336"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "\n",
    "for group in groups:\n",
    "    # English vectorization\n",
    "    print('Results for group: ', group)\n",
    "    vectorizerEN = Word2VecVectorizerEN()\n",
    "    X_train_EN = vectorizerEN.fit_transform(train[train.Group==group].title)\n",
    "    X_test_EN = vectorizerEN.transform(train[train.Group==group].title)\n",
    "    \n",
    "    # Indonesian vectorization\n",
    "    vectorizerID = Word2VecVectorizerID()\n",
    "    X_train_ID = vectorizerID.fit_transform(X_beauty_train)\n",
    "    y_train = train[train.Group==group].Category.values\n",
    "    X_test_ID = vectorizerID.transform(X_beauty_test)\n",
    "    y_test = test[test.Group==group].Category.values\n",
    "    \n",
    "    # Combination of two models\n",
    "    df_train_combined=pd.DataFrame(X_train_EN)\n",
    "    df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')\n",
    "    df_test_combined=pd.DataFrame(X_test_EN)\n",
    "    df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')\n",
    "    X_train_com=df_train_combined.values\n",
    "    X_test_com=df_test_combined.values\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "81950a0fc37a3ad3df71c78da2d65116e705b5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 1639 / 200608\n",
      "Numer of samples with no words found: 680 / 85975\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "X_train_EN = vectorizerEN.fit_transform(X_beauty_train)\n",
    "#Ytrain = y_beauty_train\n",
    "\n",
    "X_test_EN = vectorizerEN.transform(X_beauty_test)\n",
    "#Ytest = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200608, 300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_EN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 164061 / 200608\n",
      "Numer of samples with no words found: 70373 / 85975\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerID = Word2VecVectorizerID()\n",
    "X_train_ID = vectorizerID.fit_transform(X_beauty_train)\n",
    "y_train = y_beauty_train\n",
    "\n",
    "X_test_ID = vectorizerID.transform(X_beauty_test)\n",
    "y_test = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200608, 300)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=pd.DataFrame(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_combined=pd.DataFrame(X_test_EN)\n",
    "df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200608, 600), (85975, 600))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined.shape,df_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.898877412665\n",
      "test score: 0.730386740331\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(df_train_combined.values,y_train.values)\n",
    "print(\"train score\", model.score(df_train_combined.values,y_train.values))\n",
    "print(\"test score:\", model.score(df_test_combined.values,y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do the same for fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 122720 / 153791\n",
      "Numer of samples with no words found: 52577 / 65911\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerID = Word2VecVectorizerID()\n",
    "X_train_ID = vectorizerID.fit_transform(X_fashion_train)\n",
    "y_train = y_fashion_train\n",
    "\n",
    "X_test_ID = vectorizerID.transform(X_fashion_test)\n",
    "y_test = y_fashion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "_uuid": "81950a0fc37a3ad3df71c78da2d65116e705b5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 144 / 153791\n",
      "Numer of samples with no words found: 68 / 65911\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "X_train_EN = vectorizerEN.fit_transform(X_fashion_train)\n",
    "#Ytrain = y_beauty_train\n",
    "\n",
    "X_test_EN = vectorizerEN.transform(X_fashion_test)\n",
    "#Ytest = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153791, 300)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_EN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153791, 300)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=pd.DataFrame(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_combined=pd.DataFrame(X_test_EN)\n",
    "df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((153791, 600), (65911, 600))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined.shape,df_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.928266283463\n",
      "test score: 0.560968578841\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(df_train_combined.values,y_train.values)\n",
    "print(\"train score\", model.score(df_train_combined.values,y_train.values))\n",
    "print(\"test score:\", model.score(df_test_combined.values,y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "9596b96131b59bf0a17a698bc2f6ea5b15668cdc"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "29fd1d2f87e141770fee8a65e2a6624560748e7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "bcbce333fe04f936ece91eed087caab93e434658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.896150701866\n",
      "test score: 0.731177667927\n"
     ]
    }
   ],
   "source": [
    "print(\"train score\", model.score(Xtrain,Ytrain))\n",
    "print(\"test score:\", model.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "365e103eaacdc5368386b013e8f94ec876bcea31"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "2249fe3559ec3bb5f24db75f6caf7d87462fee14"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "484ae584f6ac8405025c16aa4e561ab414ac755a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40       585\n",
      "           1       0.59      0.76      0.66      6726\n",
      "           2       0.79      0.85      0.82      3282\n",
      "           3       0.88      0.80      0.84     26695\n",
      "           4       0.74      0.61      0.67     15794\n",
      "           5       0.75      0.75      0.75     16427\n",
      "           6       0.33      0.43      0.37       480\n",
      "           7       0.70      0.74      0.72      3265\n",
      "           8       0.51      0.59      0.54      1574\n",
      "           9       0.37      0.72      0.49      1268\n",
      "          10       0.44      0.59      0.50       246\n",
      "          11       0.38      0.55      0.45       849\n",
      "          12       0.85      0.73      0.79      7672\n",
      "          13       0.43      0.63      0.51       588\n",
      "          14       0.14      0.40      0.21       295\n",
      "          15       0.12      0.43      0.19        47\n",
      "          16       0.09      0.34      0.14       182\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     85975\n",
      "   macro avg       0.50      0.62      0.53     85975\n",
      "weighted avg       0.76      0.73      0.74     85975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "14c05cadf20638b9df3d8414b3b462100cc5f370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731177667927\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96f50134c6e4a12fe3e5916bc38b34d27762f45c"
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d30a206a19d8b22e907e82029983f0a669f4ff48"
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdadbef477b40760aaa312b53fc0775e465270f5"
   },
   "outputs": [],
   "source": [
    "#lr.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82c885fc59eaa5a3a557b830f8404b91ab3c7945"
   },
   "outputs": [],
   "source": [
    "#predictions_lr = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5e80f9086701b0cba1af688fb0f487444c93a91"
   },
   "outputs": [],
   "source": [
    "#print(accuracy_score(predictions_lr,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aebf7f17dd57cd6b2584de1e7274ff0758157303"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
