{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "20517a3d0aff79fef4251fd889b6e8422900c11b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "059330c4f70d8292575bb5e83a6ad832c7e29041"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9e4bf18683202567e857e8668f09d95100b48d73"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936\n"
     ]
    }
   ],
   "source": [
    "ignore_words = set(stopwords.words('english')).union(set(stopwords.words('indonesian')))\n",
    "print(len(ignore_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "49cac2747c9b75de6a074fd8ecce57b26c1ede31"
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')\n",
    "df_cat=pd.read_json('categories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 nyx sex bomb pallete natural palette\n",
       "1    etude house precious mineral any cushion pearl...\n",
       "2                             milani rose powder blush\n",
       "3                  etude house baby sweet sugar powder\n",
       "4         bedak revlon color stay aqua mineral make up\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.title.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train['Group']=df_train.image_path.map(lambda x: x[:7])\n",
    "df_test['Group']=df_test.image_path.map(lambda x: x[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "509be9648ff1ececf1eed491d130429695a62748"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(df_train,random_state=2019,stratify=df_train.Category,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=['beauty_','mobile_','fashion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some linear models\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "\n",
    "# SCM for classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build pipeline for parameter search in n_grams and and various models\n",
    "lr=LogisticRegression()\n",
    "nb=MultinomialNB()\n",
    "svc=SVC()\n",
    "# let's check first three and see which one is best\n",
    "gnb=GaussianNB()\n",
    "bnb=BernoulliNB()\n",
    "br=BayesianRidge()\n",
    "rf=RandomForestClassifier(n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  beauty_\n",
      "Accuracy  \n",
      "0.789800582724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███████████████████████████▋                                                       | 1/3 [08:48<17:36, 528.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  mobile_\n",
      "Accuracy  \n",
      "0.830687665679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [12:45<07:21, 441.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for  fashion\n",
      "Accuracy  \n",
      "0.652056166223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [27:02<00:00, 565.79s/it]"
     ]
    }
   ],
   "source": [
    "# Optimized parameters are found by GridSearch\n",
    "\n",
    "# Submit these results and see if it is really improved in leaderboard\n",
    "pipe_beauty=Pipeline([('vectorize', CountVectorizer(ngram_range=(1,3))),('model',LogisticRegression(C=0.8))])\n",
    "pipe_mobile=Pipeline([('vectorize', CountVectorizer(ngram_range=(1,3),min_df=2)),('model',LogisticRegression(C=1))])\n",
    "pipe_fashion=Pipeline([('vectorize', CountVectorizer(stop_words =ignore_words,ngram_range=(1,5))),('model',LogisticRegression(C=0.4))])\n",
    "pipe=[pipe_beauty,pipe_mobile,pipe_fashion]\n",
    "\n",
    "\n",
    "groups=['beauty_','mobile_','fashion']\n",
    "predictions_val={} # Use for ensembling model\n",
    "predictions_proba_val={} # Use for ensembling model\n",
    "predictions_all={} # check in submission file \n",
    "predictions_proba_all={} # Use for final ensembling\n",
    "for i in tqdm(range(3)):\n",
    "    print(\"Results for \", groups[i])\n",
    "    model=pipe[i]\n",
    "    X=train[train.Group==groups[i]].title\n",
    "    y=train[train.Group==groups[i]].Category\n",
    "    model.fit(X,y)\n",
    "    predictions_val[groups[i]]=model.predict(test[test.Group==groups[i]].title)\n",
    "    predictions_proba_val[groups[i]]=model.predict_proba(test[test.Group==groups[i]].title)\n",
    "    print('Accuracy  ')\n",
    "    print(accuracy_score(test[test.Group==groups[i]].Category,predictions_val[groups[i]]))\n",
    "\n",
    "    \n",
    "    model=pipe[i]\n",
    "    X=df_train[df_train.Group==groups[i]].title\n",
    "    y=df_train[df_train.Group==groups[i]].Category\n",
    "    model.fit(X,y)\n",
    "    predictions_all[groups[i]]=model.predict(df_test[df_test.Group==groups[i]].title)\n",
    "    predictions_proba_all[groups[i]]=model.predict_proba(df_test[df_test.Group==groups[i]].title)\n",
    "    \n",
    "\n",
    "\n",
    "## Wow, interesting ! It turns out that stop words helps only for fashion category!\n",
    "## Lets' list CV results for beauty, mobile  and fashion \n",
    "## beauty CV 0.784223069756\n",
    "## Mobile CV 0.825934011102\n",
    "## fashion CV 0.644946336401 with stop words\n",
    "\n",
    "# Results with stop words.\n",
    "# {'beauty_': 0.78344144628257784,\n",
    "#  'mobile_': 0.8236574564959771,\n",
    "#  'fashion': 0.6449463364011252}\n",
    "\n",
    "# Our base model CV results. I should list them here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes={}\n",
    "\n",
    "for i in range(3):\n",
    "    classes[groups[i]]=pipe[i].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beauty_': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16], dtype=int64),\n",
       " 'mobile_': array([31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "        48, 49, 50, 51, 52, 53, 54, 55, 56, 57], dtype=int64),\n",
       " 'fashion': array([17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], dtype=int64)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76545,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_all['beauty_'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57317,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_val['beauty_'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all data both validation set and training set\n",
    "# This data will be used for modeling ensembling and for final ensemble result\n",
    "for i in range(3):\n",
    "    # for ensembling\n",
    "    df=pd.DataFrame(predictions_proba_all[groups[i]])\n",
    "    df.columns=classes[groups[i]]\n",
    "    df['pred']=df.idxmax(axis=1)\n",
    "    df['itemid']=df_test[df_test.Group==groups[i]].itemid.values\n",
    "    df.to_csv(groups[i]+'_test_proba_nlp_all_data2.csv',index=False)\n",
    "    # for ensemble modeling\n",
    "    df=pd.DataFrame(predictions_proba_val[groups[i]])\n",
    "    df.columns=classes[groups[i]]\n",
    "    df['pred']=df.idxmax(axis=1)\n",
    "    df['itemid']=test[test.Group==groups[i]].itemid.values\n",
    "    df.to_csv(groups[i]+'_test_proba_nlp_val_data2.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
