{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "49cac2747c9b75de6a074fd8ecce57b26c1ede31"
   },
   "outputs": [],
   "source": [
    "ori_data = pd.read_csv('train.csv')\n",
    "submission = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_beauty = ori_data[ori_data['Category'] <= 16]\n",
    "submission_beauty = submission[submission['image_path'].str.contains(\"beauty_image\")]\n",
    "data_fashion = ori_data[(ori_data['Category'] > 16) & (ori_data['Category'] <= 30)]\n",
    "submission_fashion = submission[submission['image_path'].str.contains(\"fashion_image\")]\n",
    "data_mobile = ori_data[(ori_data['Category'] > 30) & (ori_data['Category'] <= 57)]\n",
    "submission_mobile = submission[submission['image_path'].str.contains(\"mobile_image\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "69621de04f529adf0f4df336b8d5883406e671ce"
   },
   "outputs": [],
   "source": [
    "X_beauty = data_beauty['title']\n",
    "y_beauty = data_beauty['Category']\n",
    "\n",
    "X_fashion = data_fashion['title']\n",
    "y_fashion = data_fashion['Category']\n",
    "\n",
    "X_mobile = data_mobile['title']\n",
    "y_mobile = data_mobile['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "20517a3d0aff79fef4251fd889b6e8422900c11b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "509be9648ff1ececf1eed491d130429695a62748"
   },
   "outputs": [],
   "source": [
    "X_beauty_train, X_beauty_test, y_beauty_train, y_beauty_test = train_test_split(X_beauty, y_beauty, test_size=0.3, random_state=2019)\n",
    "\n",
    "X_fashion_train, X_fashion_test, y_fashion_train, y_fashion_test = train_test_split(X_fashion, y_fashion, test_size=0.3, random_state=2019)\n",
    "\n",
    "X_mobile_train, X_mobile_test, y_mobile_train, y_mobile_test = train_test_split(X_mobile, y_mobile, test_size=0.3, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "059330c4f70d8292575bb5e83a6ad832c7e29041"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "9e4bf18683202567e857e8668f09d95100b48d73"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "?KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "6ac466ab41a52d3b2742fb96ca9efd573f8ea393"
   },
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "  def __init__(self):\n",
    "    # load in pre-trained word vectors\n",
    "    print('Loading word vectors...')\n",
    "    word2vec = {}\n",
    "    embedding = []\n",
    "    idx2word = []\n",
    "    with open('glove840b300dtxt/glove.840B.300d.txt',encoding='utf-8') as f:\n",
    "      # is just a space-separated text file in the format:\n",
    "      # word vec[0] vec[1] vec[2] ...\n",
    "      for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "    print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "    # save for later\n",
    "    self.word2vec = word2vec\n",
    "    self.embedding = np.array(embedding)\n",
    "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "    self.V, self.D = self.embedding.shape\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.lower().split()\n",
    "      vecs = []\n",
    "      for word in tokens:\n",
    "        if word in self.word2vec:\n",
    "          vec = self.word2vec[word]\n",
    "          vecs.append(vec)\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2c674be6ceb9ff2c65774780909307245434ab85"
   },
   "outputs": [],
   "source": [
    "class Word2VecVectorizerEN:\n",
    "  def __init__(self):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "      'GoogleNews-vectors-negative300.bin',\n",
    "      binary=True\n",
    "    )\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('king')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "2c674be6ceb9ff2c65774780909307245434ab85"
   },
   "outputs": [],
   "source": [
    "class Word2VecVectorizerID:\n",
    "  def __init__(self):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "      'id_sahdan.bin',\n",
    "      binary=True\n",
    "    )\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('yang')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181299    promo maybelline hyper ink eye liner black ter...\n",
       "110906                  city color all in one cream palette\n",
       "230044    mac mineralize charged water skin hydrating mi...\n",
       "207666                       jafra long wear cream blush on\n",
       "168580             bedak chanel vitalumiere compact douceur\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_beauty_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "81950a0fc37a3ad3df71c78da2d65116e705b5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 1639 / 200608\n",
      "Numer of samples with no words found: 680 / 85975\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "X_train_EN = vectorizerEN.fit_transform(X_beauty_train)\n",
    "#Ytrain = y_beauty_train\n",
    "\n",
    "X_test_EN = vectorizerEN.transform(X_beauty_test)\n",
    "#Ytest = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200608, 300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_EN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 164061 / 200608\n",
      "Numer of samples with no words found: 70373 / 85975\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerID = Word2VecVectorizerID()\n",
    "X_train_ID = vectorizerID.fit_transform(X_beauty_train)\n",
    "y_train = y_beauty_train\n",
    "\n",
    "X_test_ID = vectorizerID.transform(X_beauty_test)\n",
    "y_test = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200608, 300)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=pd.DataFrame(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_combined=pd.DataFrame(X_test_EN)\n",
    "df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200608, 600), (85975, 600))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined.shape,df_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.898877412665\n",
      "test score: 0.730386740331\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(df_train_combined.values,y_train.values)\n",
    "print(\"train score\", model.score(df_train_combined.values,y_train.values))\n",
    "print(\"test score:\", model.score(df_test_combined.values,y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do the same for fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 122720 / 153791\n",
      "Numer of samples with no words found: 52577 / 65911\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerID = Word2VecVectorizerID()\n",
    "X_train_ID = vectorizerID.fit_transform(X_fashion_train)\n",
    "y_train = y_fashion_train\n",
    "\n",
    "X_test_ID = vectorizerID.transform(X_fashion_test)\n",
    "y_test = y_fashion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "_uuid": "81950a0fc37a3ad3df71c78da2d65116e705b5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 144 / 153791\n",
      "Numer of samples with no words found: 68 / 65911\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = GloveVectorizer()\n",
    "vectorizerEN = Word2VecVectorizerEN()\n",
    "X_train_EN = vectorizerEN.fit_transform(X_fashion_train)\n",
    "#Ytrain = y_beauty_train\n",
    "\n",
    "X_test_EN = vectorizerEN.transform(X_fashion_test)\n",
    "#Ytest = y_beauty_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153791, 300)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_EN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153791, 300)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=pd.DataFrame(X_train_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_combined=df_train_combined.join(pd.DataFrame(X_train_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_combined=pd.DataFrame(X_test_EN)\n",
    "df_test_combined=df_test_combined.join(pd.DataFrame(X_test_ID),rsuffix='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((153791, 600), (65911, 600))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined.shape,df_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.928266283463\n",
      "test score: 0.560968578841\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(df_train_combined.values,y_train.values)\n",
    "print(\"train score\", model.score(df_train_combined.values,y_train.values))\n",
    "print(\"test score:\", model.score(df_test_combined.values,y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "9596b96131b59bf0a17a698bc2f6ea5b15668cdc"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "29fd1d2f87e141770fee8a65e2a6624560748e7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "bcbce333fe04f936ece91eed087caab93e434658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.896150701866\n",
      "test score: 0.731177667927\n"
     ]
    }
   ],
   "source": [
    "print(\"train score\", model.score(Xtrain,Ytrain))\n",
    "print(\"test score:\", model.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "365e103eaacdc5368386b013e8f94ec876bcea31"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "2249fe3559ec3bb5f24db75f6caf7d87462fee14"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "484ae584f6ac8405025c16aa4e561ab414ac755a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40       585\n",
      "           1       0.59      0.76      0.66      6726\n",
      "           2       0.79      0.85      0.82      3282\n",
      "           3       0.88      0.80      0.84     26695\n",
      "           4       0.74      0.61      0.67     15794\n",
      "           5       0.75      0.75      0.75     16427\n",
      "           6       0.33      0.43      0.37       480\n",
      "           7       0.70      0.74      0.72      3265\n",
      "           8       0.51      0.59      0.54      1574\n",
      "           9       0.37      0.72      0.49      1268\n",
      "          10       0.44      0.59      0.50       246\n",
      "          11       0.38      0.55      0.45       849\n",
      "          12       0.85      0.73      0.79      7672\n",
      "          13       0.43      0.63      0.51       588\n",
      "          14       0.14      0.40      0.21       295\n",
      "          15       0.12      0.43      0.19        47\n",
      "          16       0.09      0.34      0.14       182\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     85975\n",
      "   macro avg       0.50      0.62      0.53     85975\n",
      "weighted avg       0.76      0.73      0.74     85975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "14c05cadf20638b9df3d8414b3b462100cc5f370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731177667927\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96f50134c6e4a12fe3e5916bc38b34d27762f45c"
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d30a206a19d8b22e907e82029983f0a669f4ff48"
   },
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdadbef477b40760aaa312b53fc0775e465270f5"
   },
   "outputs": [],
   "source": [
    "#lr.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82c885fc59eaa5a3a557b830f8404b91ab3c7945"
   },
   "outputs": [],
   "source": [
    "#predictions_lr = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5e80f9086701b0cba1af688fb0f487444c93a91"
   },
   "outputs": [],
   "source": [
    "#print(accuracy_score(predictions_lr,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aebf7f17dd57cd6b2584de1e7274ff0758157303"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
